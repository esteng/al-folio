---
title: Exploring fine-grained semantic inferences cross-lingually
author: Elias Stengel-Eskin
summary: Exploring fine-grained semantic inferences cross-lingually 
date: 2020-06-24
math: true
diagram: true
categories:
  - decomp
  - linguistics
tags:
  - comp-ling
  - decomp
projects:
  - decomp
image:
  placement: 3
  caption: 
featured: yes
bibliography: decomp.bib
---



<p>Consider the following two scenarios:</p>
<ol style="list-style-type: decimal">
<li><p>Derek was over for dinner at Lisa's house. After dinner, he offered to do the dishes, but as he was picking up one of the plates his grip slipped and he dropped it. Later, when telling her friend about the night, Lisa said, &quot;Derek broke the plate.&quot;</p></li>
<li><p>Derek was over for dinner at Lisa's house. Lisa claimed that she bought special &quot;unbreakable&quot; plates and challenged Derek to break one. He promptly smacked the plate against the edge of the counter, and broke it. Later, when telling her friend about the night, Lisa said, &quot;Derek broke the plate.&quot;</p></li>
</ol>
<table>
<thead>
<tr class="header">
<th>1</th>
<th>2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><img src="accident.jpg" alt="Derek broke the plate accidentally" width="300"/></td>
<td><img src="purpose.jpg" alt="Derek broke the plate on purpose" width="300"/></td>
</tr>
</tbody>
</table>
<p>Both times, the statement &quot;Derek broke the plate&quot; remains unchanged. But based on the different scenarios, we as readers draw very different conclusions. Evidence suggests that even toddlers are able to draw inferences about intentionality and volition <span class="citation">(Vaish, Carpenter, and Tomasello 2010)</span>.<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a> Inferences like that in (2), Derek meant to break the plate, while in (1) it was an accident. Furthermore, different scenarios might evoke different levels of volition; we could easily imagine a range of set-ups where Derek is more or less volitional, between the two extremes laid out above. We can also draw a much broader range of inferences from these sentences; for example, we know that Derek is sentient while the plate is not, and that the plate physically changed during the process, but Derek probably wasn't. We know that the plate probably doesn't exist anymore, but Derek does. The list goes on...</p>
<p>This raises a few key questions: how is it that identical sentences can evoke a range of different inferences? What kinds of inferences do we draw from language? What other hidden knowledge is lying just under the surface of the language we speak?</p>
<p>A rich array of work has looked at these questions, including <span class="citation">Dowty (1991)</span>, who introduced a number of inferences, including &quot;volition&quot;, &quot;awareness&quot;, &quot;sentience&quot;, &quot;change of state&quot;, and &quot;existed before/during/after&quot;. From there, <span class="citation">D. Reisinger et al. (2015)</span>, <span class="citation">White et al. (2016)</span>, <span class="citation">Govindarajan, Van Durme, and White (2019)</span>, and <span class="citation">Vashishtha, Van Durme, and White (2019)</span> annotated a corpus of English sentences these properties (among others) and began modeling them. I myself joined this effort fairly late, contributing to <span class="citation">White et al. (2019)</span>, which consolidated annotations from across these works into one dataset, the Universal Decompositional Semantics Dataset, or <a href="http://decomp.io">UDSv1.0</a>. My main contribution to this line of work has been working on a parsing model, which learns to automatically extract these inferences from text <span class="citation">(Stengel-Eskin et al. 2020)</span>.</p>
<p>By way of starting, I'll try to summarize the different types of annotations in the dataset. The dataset gives each property a score from -3 to 3, with 3 being &quot;very likely&quot; and -3 being &quot;very unlikely.&quot; The words the annotation applies to are given in bold.</p>
<table>
<colgroup>
<col width="13%" />
<col width="39%" />
<col width="46%" />
</colgroup>
<thead>
<tr class="header">
<th>Annotation</th>
<th>Description</th>
<th>Examples</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Factuality</strong></td>
<td>Factuality inferences represent how likely (or unlikely) a listener thinks a scenario that is to have occurred.</td>
<td>Jo <strong>left</strong> (3), Jo didn’t <strong>leave</strong> (-3), Jo thought that Cole had <strong>left</strong> (-1)</td>
</tr>
<tr class="even">
<td><strong>Genericity</strong></td>
<td>Genericity refers to inferences about the generality of events or event participants</td>
<td><em>Ex. property: genericity-predicate-particular</em>: Amy <strong>ate</strong> oats for breakfast today (3), Amy <strong>ate</strong> oats for breakfast every day (-3)</td>
</tr>
<tr class="odd">
<td><strong>Time</strong></td>
<td>Temporal inferences are inferences about how long events might take</td>
<td><em>Ex. property: time-duration-minutes</em>: Tom <strong>left</strong> (-3), Tom was <strong>singing</strong> (3)</td>
</tr>
<tr class="even">
<td><strong>Word Sense</strong></td>
<td>Words can have different senses/supersenses (e.g. <em>bank</em> as a place to keep money (phyiscal location) vs. the <em>bank</em> of a river, (geographical feature)). These sense can apply to differing degrees.</td>
<td><em>Ex. property: &quot;person&quot; supersense</em> Sandy led <strong>Rufus</strong> by a leash (-3), <strong>Sandy</strong> led Rufus by a leash (3)</td>
</tr>
<tr class="odd">
<td><strong>Semantic proto-roles</strong></td>
<td>SPR properties (introduced by <span class="citation">Dowty (1991)</span>) capture properties typically associated with either agents (the person/thing doing the acting in a sitation) and patients (the person/thing that's being acted upon), like awareness and volition (agent properties) or change of state and being created/destroyed (patient properties)</td>
<td><em>Ex. property: volition</em> <strong>Derek</strong> broke his arm (-3), <strong>Derek</strong> broke the wishbone (3) </br> <em>Ex. property: was used</em> The fragile vase was shipped with <strong>bubble-wrap</strong> (3), The fragile vase was shipped with <strong>haste</strong> (-3)</td>
</tr>
</tbody>
</table>
<div id="excavation-via-other-languages" class="section level2">
<h2>Excavation via other languages</h2>
<p>When we look at these questions from one linguistic lens alone, we get an impoverished view. Some inferences will present themselves readily, while others will be purely contextual. For example from the English point of view, information on when an event happened is often presented explicitly in the tense of the verb; in another language (such as Mandarin) this information might need to be inferred from context, much like how Derek's level volition in breaking the plate in English needs to be inferred.</p>
<p>Other languages offer different lenses through which to view these semantic inferences by varying what they make explicit and what is kept below the surface. Think of semantics as a lost city or desert ruin, with different languages acting as different winds, shifting the surface-level sand to uncover different aspects of the same semantic structure.</p>
</div>
<div id="back-to-derek-and-the-plate" class="section level2">
<h2>Back to Derek and the plate</h2>
<p>Let's revisit Derek, but this time in a different linguistic setting -- say, Mexico City. Where in English, we'd use the same construction in both scenarios (volitional and non-volitional), in Spanish, we'd probably use a different construction. In scenarios (1) and (2), we'd say something like</p>
<ol style="list-style-type: decimal">
<li><table>
<thead>
<tr class="header">
<th><em>Spanish</em></th>
<th>Se</th>
<th>le</th>
<th>rompió</th>
<th>el plato</th>
<th>a</th>
<th>Derek</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><em>Direct English gloss</em></td>
<td>Itself</td>
<td>to him</td>
<td>broke</td>
<td>the plate</td>
<td>to</td>
<td>Derek</td>
</tr>
<tr class="even">
<td><em>Rough English gloss</em></td>
<td>The</td>
<td>plate</td>
<td>broke</td>
<td>itself</td>
<td>to</td>
<td>Derek</td>
</tr>
<tr class="odd">
<td><em>English translation</em></td>
<td></td>
<td></td>
<td>Derek</td>
<td>broke</td>
<td>the plate</td>
<td></td>
</tr>
</tbody>
</table></li>
<li><table>
<thead>
<tr class="header">
<th><em>Spanish</em></th>
<th>Derek</th>
<th>rompió</th>
<th>el plato</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><em>En. gloss</em></td>
<td>Derek</td>
<td>broke</td>
<td>the plate</td>
</tr>
<tr class="even">
<td><em>En. translation</em></td>
<td>Derek</td>
<td>broke</td>
<td>the plate</td>
</tr>
</tbody>
</table></li>
</ol>
<p>Both can translate to &quot;Derek broke the plate&quot; in English, but the first utterance indicates that it was an accident. A direct gloss of each sentence is immediately below the example. Funnily enough, the direct gloss here looks a lot like what we might find in German!</p>
<ol style="list-style-type: decimal">
<li><table>
<thead>
<tr class="header">
<th><em>German</em></th>
<th>Der</th>
<th>Teller</th>
<th>ist</th>
<th>dem</th>
<th>Derek</th>
<th>zerbrochen</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><em>En. gloss</em></td>
<td>The-NOM</td>
<td>plate-NOM</td>
<td>is-AUX</td>
<td>the-DAT</td>
<td>Derek-DAT</td>
<td>broken</td>
</tr>
<tr class="even">
<td><em>Rough En. gloss</em></td>
<td>The</td>
<td>plate</td>
<td>broke</td>
<td>to</td>
<td>Derek</td>
<td></td>
</tr>
<tr class="odd">
<td><em>En. translation</em></td>
<td></td>
<td>Derek</td>
<td>broke</td>
<td>the</td>
<td>plate</td>
<td></td>
</tr>
</tbody>
</table></li>
<li><table>
<thead>
<tr class="header">
<th>Derek</th>
<th>hat</th>
<th>den</th>
<th>Teller</th>
<th>zerbrochen.</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Derek</td>
<td>has</td>
<td>the-ACC</td>
<td>plate-ACC</td>
<td>broken</td>
</tr>
<tr class="even">
<td>Derek</td>
<td>broke</td>
<td>the</td>
<td>plate</td>
<td><a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a></td>
</tr>
</tbody>
</table></li>
</ol>
<p>So looking at two other languages tells us that while English doesn't necessarily make the distinction between volitional and non-volitional plate breaking (at least in the active voice), other languages do!<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a></p>
</div>
<div id="what-about-some-other-inferences" class="section level2">
<h2>What about some other inferences</h2>
<p>Tired of Derek and his plates? Me too. Why not take a step up the linguistic family tree from Spanish and look at its parent, Latin. Latin is a fantastic language for exploring these kinds of inferences for a few reasons. The first is that its a morphologically rich language -- many of the grammatical relations which are encoded by word position in other languages (e.g. subject, predicate, and object in English) are encoded directly on the words. This means that word order is much less important. It also means that wealth of semantic information is encoded in the morphology of a word.</p>
<p>Another reason Latin is great for looking at these inferences is the way it's taught. Nouns (and their corresponding adjectives) have cases in Latin, which are different endings to the same stem (much like how verbs in English have different endings for different tenses/moods/persons). The cases are nominative, genitive, dative, accusative, ablative, and vocative (and sometimes locative), all with different uses. To help students remember which cases are used when, the cases come with handy names that are taught in textbooks, like &quot;<em>the ablative of agent</em>&quot; or &quot;<em>the dative of reference.</em>&quot; We can match some of these handy mnemonics directly to certain inferences described in <span class="citation">Dowty (1991)</span>. For example, the &quot;was used&quot; property fits well with the <em>ablative of instrument</em>, where an ablative ending tells us something was used as a tool in an action, i.e.</p>
<table>
<thead>
<tr class="header">
<th>Caesar</th>
<th>gladiis</th>
<th>occidus</th>
<th>est</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Caesar-NOM</td>
<td>swords-ABL</td>
<td>killed-NOM</td>
<td>is-AUX</td>
</tr>
<tr class="even">
<td>Caesar</td>
<td>with swords</td>
<td>killed</td>
<td>was</td>
</tr>
<tr class="odd">
<td>Caesare</td>
<td>was</td>
<td>killed</td>
<td>with swords</td>
</tr>
</tbody>
</table>
<p>Similarly, Dowty's &quot;was for the benefit of&quot; property demands nothing less than the dative, in this case often known as the <em>dative of advantage/disadvantage</em>. <em>Cui bono</em> is a famous example of this.<a href="#fn4" class="footnoteRef" id="fnref4"><sup>4</sup></a></p>
<p>These mnemonic devices not only help students learn Latin, but also help to expose some of the underlying semantic features of the language.</p>
</div>
<div id="genericity" class="section level2">
<h2>Genericity</h2>
<p>Genericity inferences pertain to how particular or abstract a predicate or argument is. For example, it's clear that &quot;dogs&quot; in &quot;My uncle Roger's dogs Fifi and Fido&quot; is different from &quot;dogs&quot; in &quot;my brother is afraid of dogs&quot;, in that the first &quot;dogs&quot; is very particular, while the second one applies to more of a natural kind. Similarly, predicates can be more or less particular or general. Consider:</p>
<ol start="3" style="list-style-type: decimal">
<li>Marie ate oatmeal for breakfast every day.</li>
<li>Marie ate oatmeal for breakfast yesterday.</li>
</ol>
<p>The &quot;ate&quot; in (3) is different from the &quot;ate&quot; in (4), which encompases a broader range of instances of an &quot;eating&quot; event. French makes this distinction quite clear on the surface level:</p>
<ol start="3" style="list-style-type: decimal">
<li><table>
<thead>
<tr class="header">
<th>Marie</th>
<th>a</th>
<th>mangé</th>
<th>du</th>
<th>gruau</th>
<th>pour</th>
<th>son</th>
<th>petit</th>
<th>déjeuner</th>
<th>hier</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Marie</td>
<td>has</td>
<td>eaten</td>
<td>of the</td>
<td>oatmeal</td>
<td>for</td>
<td>her</td>
<td>small</td>
<td>lunch</td>
<td>yesterday</td>
</tr>
<tr class="even">
<td>Marie</td>
<td>ate</td>
<td>oatmeal</td>
<td>for</td>
<td>breakfast</td>
<td>yesteray</td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table></li>
<li><table>
<thead>
<tr class="header">
<th>Marie</th>
<th>mangeait</th>
<th>du</th>
<th>gruau</th>
<th>pour</th>
<th>son</th>
<th>petit</th>
<th>déjeuner</th>
<th>tous</th>
<th>les</th>
<th>jours</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Marie</td>
<td>ate-PROG</td>
<td>of the</td>
<td>oatmeal</td>
<td>for</td>
<td>her</td>
<td>small</td>
<td>lunch</td>
<td>all</td>
<td>the</td>
<td>days</td>
</tr>
<tr class="even">
<td>Marie</td>
<td>ate (imperf.)</td>
<td>oatmeal</td>
<td>for</td>
<td>breakfast</td>
<td>every</td>
<td>day</td>
<td></td>
</tr>
</tbody>
</table></li>
</ol>
<p>Here, we have two different tenses for actions in the past which were repeated or more general, and those which are more specific instances. These same tenses (imperfect and perfect) relate also to time duration annotations, which can be found in the UDS dataset <span class="citation">(White et al. 2019)</span>.</p>
</div>
<div id="awarenesssentience" class="section level2">
<h2>Awareness/sentience</h2>
<p>Awareness and sentience are probably my favorite proto-roles; what could better describe the impressive human capacity for language than the entirely unconscious ability to rapidly draw inferences about philosophically layered concepts like awareness and sentience? German (another morphologically rich language) makes certain inferences about awareness and sentience quite clear in its use of case with certain verbs. In English, a speaker surprised by something might say:</p>
<ol start="5" style="list-style-type: decimal">
<li>I don't believe <em>it</em>!</li>
</ol>
<p>While an incredulous person might say:</p>
<ol start="6" style="list-style-type: decimal">
<li>I don't believe <em>him</em>!</li>
</ol>
<p>where the &quot;it&quot; in (5) is clearly non-sentient (i.e. a news story, a state of affairs, a juicy piece of gossip, etc.) while &quot;him&quot; in (6) is sentient. In German, these two objects, while arguments of the same verb, take different cases (accusative and dative, respectively):</p>
<ol start="5" style="list-style-type: decimal">
<li><table>
<thead>
<tr class="header">
<th>Ich</th>
<th>glaube</th>
<th><em>es</em></th>
<th>nicht!</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>I</td>
<td>believe</td>
<td>it-ACC</td>
<td>not</td>
</tr>
<tr class="even">
<td>I</td>
<td>don't</td>
<td>believe</td>
<td>it</td>
</tr>
</tbody>
</table></li>
<li><table>
<thead>
<tr class="header">
<th>Ich</th>
<th>glaube</th>
<th><em>ihm</em></th>
<th>nicht!</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>I</td>
<td>believe</td>
<td>him-DAT</td>
<td>not</td>
</tr>
<tr class="even">
<td>I</td>
<td>don't</td>
<td>believe</td>
<td>him</td>
</tr>
</tbody>
</table></li>
</ol>
<p>A German speaker thus explicitly represents beliefs about the sentience/non-sentience of an object while choosing a case for an object.</p>
</div>
<div id="conclusions" class="section level1">
<h1>Conclusions</h1>
<p>By no means am I suggesting, with the examples above, that these inferences are impossible to draw in different languages, or even necessarily more difficult. All languages are infinitely expressive, and given enough clarification, any inferences about proto-roles, genericity, time duration, or word sense can be made as plain as in any other language. I instead hope to draw attention to the ways that languages encode some of these inferences explicitly in the grammar, lending support to their status as real linguistic concepts rather than figments of the imagination.</p>
<p>Nor do I want to give the impression that speakers of these different languages differ in their judgements of these inferences, or that having the inferences explicitly represented in the grammar or morphology somehow increases our awareness of them. I don't know of any research to this effect, and have not experienced this myself. In fact, the miracle is that all of this happens largely unconsciously, and that there seems to be wide agreement between speakers on these inferences. That all speakers of a language can even agree on a meaning for what <em>is</em> said is miraculous, but that they can also to a large extent on what is <em>not</em> said is even more astounding.</p>
<p>Finally, these are just <em>some</em> examples from <em>some</em> languages that I happen to be familiar with. I'd love to find more examples like these, so if you can think of ones in other languages (especially non-<a href="https://en.wikipedia.org/wiki/Psychology#WEIRD_bias">WEIRD</a> languages!) please don't hesitate to reach out! Similarly, if you can think of counter-examples in these languages or others, shoot me a message.</p>
</div>
<div id="references" class="section level1 unnumbered">
<h1>References</h1>
<div id="refs" class="references">
<div id="ref-dowty.d.1991">
<p>Dowty, David. 1991. “Thematic Proto-Roles and Argument Selection.” <em>Language</em> 67 (3). Linguistic Society of America: 547–619.</p>
</div>
<div id="ref-govindarajan.v.2019">
<p>Govindarajan, Venkata, Benjamin Van Durme, and Aaron Steven White. 2019. “Decomposing Generalization: Models of Generic, Habitual, and Episodic Statements.” <em>Transactions of the Association for Computational Linguistics</em> 7: 501–17.</p>
</div>
<div id="ref-reisinger.d.2015">
<p>Reisinger, Drew, Rachel Rudinger, Francis Ferraro, Craig Harman, Kyle Rawlins, and Benjamin Van Durme. 2015. “Semantic Proto-Roles.” <em>Transactions of the Association for Computational Linguistics</em> 3: 475–88.</p>
</div>
<div id="ref-stengel-eskin.e.2020">
<p>Stengel-Eskin, Elias, Aaron Steven White, Sheng Zhang, and Benjamin Van Durme. 2020. “Universal Decompositional Semantic Parsing.” In <em>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</em>, 8427–39. Online: Association for Computational Linguistics. <a href="https://www.aclweb.org/anthology/2020.acl-main.746" class="uri">https://www.aclweb.org/anthology/2020.acl-main.746</a>.</p>
</div>
<div id="ref-vaish.a.2010">
<p>Vaish, Amrisha, Malinda Carpenter, and Michael Tomasello. 2010. “Young Children Selectively Avoid Helping People with Harmful Intentions.” <em>Child Development</em> 81 (6). Wiley Online Library: 1661–9.</p>
</div>
<div id="ref-vashishtha.s.2019">
<p>Vashishtha, Siddharth, Benjamin Van Durme, and Aaron Steven White. 2019. “Fine-Grained Temporal Relation Extraction.” In <em>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</em>, 2906–19. Florence, Italy: Association for Computational Linguistics.</p>
</div>
<div id="ref-white.a.2016">
<p>White, Aaron Steven, Drew Reisinger, Keisuke Sakaguchi, Tim Vieira, Sheng Zhang, Rachel Rudinger, Kyle Rawlins, and Benjamin Van Durme. 2016. “Universal Decompositional Semantics on Universal Dependencies.” In <em>Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</em>, 1713–23. Austin, TX: Association for Computational Linguistics.</p>
</div>
<div id="ref-white.a.2019">
<p>White, Aaron Steven, Elias Stengel-Eskin, Siddharth Vashishtha, Venkata Govindarajan, Dee Ann Reisinger, Tim Vieira, Keisuke Sakaguchi, et al. 2019. “The Universal Decompositional Semantics Dataset and Decomp Toolkit.” <em>ArXiv Preprint ArXiv:1909.13851</em>.</p>
</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>based on the finding that toddlers show preferences for helping individuals who are perceived to have caused a harmful action accidentally over those who caused the same action on purpose<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>Where needed, I've included a linguistic gloss (basically a word-for-word translation), with cases like NOM (nominative), ACC (accusative), DAT (dative), etc., as well as a &quot;rough gloss&quot; which gives a more English-ified word-for-word translation of the original sentence, to be more comprehensible for those who aren't familiar with the case system.<a href="#fnref2">↩</a></p></li>
<li id="fn3"><p>I specify the active voice, since we often use the passive voice to indicate a lack of volition, i.e. &quot;The plate was broken by Derek,&quot; although this isn't quite the same as the Spanish and German examples. We also have verbs that optionally take an object, like &quot;break,&quot; that can be used to express a similar notion, i.e. &quot;The plate broke,&quot; but there is no easy way to simultaneously express Derek's involvement.<a href="#fnref3">↩</a></p></li>
<li id="fn4"><p><em>cui bono</em> is actually a rare &quot;double dative&quot; composed of a <em>dative of advantage</em> and a <em>dative of reference</em>, literally, &quot;for a benefit to whom?&quot;<a href="#fnref4">↩</a></p></li>
</ol>
</div>
