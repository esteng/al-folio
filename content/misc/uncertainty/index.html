---
title: Annotator Instructions
author: Elias Stengel-Eskin
summary: Instructions for Annotating Uncertainty HIT
date: 2021-12-01
math: true
diagram: true
categories:
  - misc
tags:
  - misc
projects:
  - none
image:
  placement: 3
  caption: 
featured: no
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>


<div id="table-of-contents" class="section level2">
<h2>Table of Contents</h2>
<ol style="list-style-type: decimal">
<li><a href="#introduction">Introduction</a>
<ol style="list-style-type: lower-alpha">
<li><a href="#about-the-interface">About the interface</a></li>
</ol></li>
<li><a href="#description-of-categories">Description of Categories</a>
<ol style="list-style-type: lower-alpha">
<li><a href="#low-quality-image">Low Quality Image</a></li>
<li><a href="#invalid-question-or-spam-answer">Invalid Question/Spam Answer</a></li>
<li><a href="#difficult-or-time-consuming">Difficult/Time Consuming</a></li>
<li><a href="#synonyms-or-hypernyms">Synonyms/Hypernyms</a></li>
<li><a href="#answer-not-present-or-guessing">Answer Not Present/Guessing</a></li>
<li><a href="#ambiguous">Ambiguous</a></li>
<li><a href="#choice-of-many">Choice of Many</a></li>
<li><a href="#disagreements-of-meaning">Disagreements of Meaning</a></li>
</ol></li>
</ol>
</div>
<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p>For the follow question about the image, the answers provided may differ. Think of each answer as coming from a different person. Some people might disagree about the answers to the question.</p>
<p>You will see an image and a question about the image, along with a set of responses from different people. All the responses differ (at least superficially). In some cases, the difference is just a matter of different spellings of the same word or concept. However, in other cases, the disagreement is more pronounced (e.g. half of the annotators said “yes”, the other half said “no”).
Below the image and question, there is a set of labels that identify reasons why annotators may have disagreed. <strong>Please note that you’re not being asked to answer the question itself, or to decide which answer was correct</strong>. Instead, we would like you to try to infer the reason <strong>why</strong> people disagreed.</p>
<p>In this document, descriptions and examples are given for each of these labels.
<strong>Please label with image-question-answer set with the labels, or, if none apply, select “Other” and provide a brief explanation in the text box.</strong></p>
<div id="about-the-interface" class="section level3">
<h3>About the interface</h3>
<p>The interface shows the image on the top left, the question and answers on the top right, and the choices on the bottom.
There is an interface on the right side of the image which allows you to zoom in on the image if needed (you are unlikely to need this).
Some choices trigger follow-up questions. These will appear to the right of the existing choices.
With a long image, the choices may be at the bottom of the screen, initially out of view. Please make sure to scroll down to look at all the options before annotating the example.
Each choice has a superscript digit or letter next to it; by pressing that key on your keyboard, you can toggle the choice on or off. Pressing the Control + Enter key combo will submit the task. These shortcuts can help speed up the task.
Note that for a given example, multiple choices can be selected, as in some cases examples will span multiple labels.
<strong>Please try to label each example with as few labels as possible.</strong> Ideally, each of the examples should receive only one label. We have included the option to annotate with multiple labels, but please use this feature sparingly.</p>
</div>
</div>
<div id="description-of-categories" class="section level2">
<h2>Description of Categories</h2>
<div id="low-quality-image" class="section level3">
<h3>Low Quality Image</h3>
<p>Some images are low quality: for example, they may be blurry or dark. This can lead to annotator disagreement, since the annotators might see the image differently.</p>
<div id="example" class="section level4">
<h4>Example:</h4>
<ul>
<li>Question: What are the girls holding?</li>
<li>Answers: “board”, “donut”, “laptop”, “unknown”, “tablet”, “keyboard”, “computer”, “laptop computer”, “laptop”, “laptop”</li>
<li>Image: <img src="images/COCO_train2014_000000444945.jpg" alt="first image" /></li>
</ul>
</div>
</div>
<div id="invalid-question-or-spam-answer" class="section level3">
<h3>Invalid Question or Spam answer</h3>
<p>This category encompasses two possibilities: invalid questions and spam answers.
Both the questions and answers were generated by annotators, who sometimes produce nonsense.
Some questions are unrelated to the image or generally unanswerable.
Other times, annotators provide nonsense answers to valid questions; this may be deliberate, or maybe they did not understand the question.
We treat these the same way.</p>
<div id="example-invalid-question" class="section level4">
<h4>Example (Invalid Question):</h4>
<ul>
<li>Question: what are</li>
<li>Answers: “lights”, “lamp”, “lamps”, “pillows”, “hotel”</li>
<li>Image: <img src="images/COCO_train2014_000000109928.jpg" alt="second image" /></li>
</ul>
</div>
<div id="example-spam-answer" class="section level4">
<h4>Example (Spam Answer):</h4>
<ul>
<li>Question: Is the man reading?</li>
<li>Answers: “yes”, “yes”, “yes”, “<strong>magazine</strong>”</li>
<li>Image: <img src="images/COCO_train2014_000000441544.jpg" alt="spam answer" /></li>
</ul>
</div>
</div>
<div id="difficult-or-time-consuming" class="section level3">
<h3>Difficult or Time Consuming</h3>
<p>Questions can be impossible, very difficult, or time-consuming to answer. For example, the question may ask the annotator to count many small objects, making it very hard to get an exact answer.</p>
<div id="example-1" class="section level4">
<h4>Example:</h4>
<ul>
<li>Question: How many cars are there?</li>
<li>Answers: “2”, “7”, “2”, “1”, “1”, “6”, “6”, “3”, “many”, “4”</li>
<li>Image: <img src="images/COCO_train2014_000000445113.jpg" alt="difficult" /></li>
</ul>
</div>
</div>
<div id="synonyms-or-hypernyms" class="section level3">
<h3>Synonyms or Hypernyms</h3>
<p>Annotators might differ slightly in how they phrase an answer, or identify objects at different levels of granularity. Crucially, for this label, all the annotations should refer to the <strong>same object or concept</strong>.</p>
<div id="example-synonyms" class="section level4">
<h4>Example (synonyms):</h4>
<ul>
<li>Question: What is the person holding?</li>
<li>Answers: “tennis racket”, “tennis racket”, “tennis racket”, “racquet”, “racket”, “tennis racket”, “tennis racket”, “racquet”, “racket”, “tennis racket”</li>
<li>Image: <img src="images/COCO_train2014_000000442961.jpg" alt="synonyms" /></li>
</ul>
</div>
<div id="example-hypernyms" class="section level4">
<h4>Example (hypernyms):</h4>
<ul>
<li>Question: What sits on the left hand side of the bowl?</li>
<li>Answers: “container”, “jug”, “container”, “bottle”</li>
<li>Image: <img src="images/COCO_train2014_000000438671.jpg" alt="hypernyms" /></li>
</ul>
</div>
</div>
<div id="answer-not-present-or-guessing" class="section level3">
<h3>Answer not Present or Guessing</h3>
<p>Questions sometimes are asking for information not visible in the image (e.g. questions about objects partially out of the frame, or not depictable in an image). Annotators will often differ in their answers for such images.
Clicking this option will open another annotation menu to the right, with the following labels:</p>
<div id="example-motion" class="section level4">
<h4>Example (motion):</h4>
<p>The question asks about the motion of an object; since we’re dealing with images, this can be hard to infer.</p>
<ul>
<li>Question: Is the train moving?</li>
<li>Answers: “no”, “no”, “no”, “no”, “yes”, “no”, “yes”, “yes”, “yes”, “yes”</li>
<li>Image: <img src="images/COCO_train2014_000000441034.jpg" alt="motion" /></li>
</ul>
</div>
<div id="example-out-of-view" class="section level4">
<h4>Example (out of view):</h4>
<p>The question asks about an object or event that is out of view of the image</p>
<ul>
<li>Question: What is inside the yellow plastic object?</li>
<li>Answers: “groceries”, “stuff”, “products”, “toiletries”, “stuff”, “food”, “food”, “luggage”,</li>
<li>Image: <img src="images/COCO_train2014_000000445462.jpg" alt="out-of-view" /></li>
</ul>
</div>
<div id="example-predicting-the-future" class="section level4">
<h4>Example (predicting the future):</h4>
<p>The question asks about whether something will happen in the future.</p>
<ul>
<li>Question: Is the woman going to eat it all?</li>
<li>Answers: “no”, “yes”, “no”, “no”, “no”, “no”, “no”, “yes”, “no”</li>
<li>Image: <img src="images/COCO_train2014_000000439576.jpg" alt="predicting future" /></li>
</ul>
</div>
<div id="example-hypothetical" class="section level4">
<h4>Example (hypothetical):</h4>
<p>The question asks whether something hypothetically would happen.</p>
<ul>
<li>Question: Could passenger be boarding?</li>
<li>Answers: “yes”, “no”, “no”, “yes”, “yes”, “no”</li>
<li>Image: <img src="images/COCO_train2014_000000444210.jpg" alt="hypothetical" /></li>
</ul>
</div>
<div id="example-domain-knowledge" class="section level4">
<h4>Example (domain knowledge):</h4>
<p>The question might be any one of the above (motion, out of view, prediciting the future, hypothetical), but the answers indicate that some people give a certain answer based on domain knowledge, while others might give a different, less informed answer. This happens often with sports.</p>
<ul>
<li>Question: What trick is he performing?</li>
<li>Answers: “rail riding”, “ollie”, “skateboard trick”, “rail grinding”, “railslide”, “rail slide”, “grinding”, “slide”, “loop”, “sliding on rail”</li>
<li>Image: <img src="images/COCO_train2014_000000044327.jpg" alt="domain" /></li>
</ul>
<p>There is also an “other” option which will prompt you to provide your own answer.</p>
</div>
</div>
<div id="ambiguous" class="section level3">
<h3>Ambiguous</h3>
<p>This category is very broad, and may overlap with other categories. At the end of this instruction document are some examples to help distinguish ambiguous from other related categories.
In some cases, the image is ambiguous; in other cases, it is the question. It is also possible for both to be ambiguous.</p>
<div id="example-image" class="section level4">
<h4>Example (image)</h4>
<p>This option should be used when an image is visually ambiguous.</p>
<ul>
<li>Question: How many lamps are on the counter ?</li>
<li>Answers: “1”, “1”, “2”, “1”, “2”, “2”, “1”</li>
<li>Image: <img src="images/COCO_train2014_000000465213.jpg" alt="visually-ambiguous" /></li>
</ul>
</div>
<div id="example-question" class="section level4">
<h4>Example (question)</h4>
<p>This option should be used when a question is linguistically ambiguous.
<strong>This includes questions where annotators could take a different perspective to get different answers (e.g. left vs right)</strong></p>
<ul>
<li>Question: In which direction is the wave moving?</li>
<li>Answers: “south”, “forward”, “right”, “forward”, “down”, “right”, “toward beach”, “right”, “left to right”, “left”</li>
<li>Image: <img src="images/COCO_train2014_000000440314.jpg" alt="blah" /></li>
</ul>
</div>
</div>
<div id="choice-of-many" class="section level3">
<h3>Choice of many</h3>
<p>When annotators are asked to choose one thing from an image and there are many options, they will often choose different ones. This happens frequently with text or colors.</p>
<div id="example-text" class="section level4">
<h4>Example (text)</h4>
<ul>
<li>Question: What does the boy’s shirt say?</li>
<li>Answers: “eagles”, “miami eagles legends, all state champions usa”, “america beautiful”, “miami eagles usa”, “m”, “miami eagles”, “miami eagles”</li>
<li>Image: <img src="images/COCO_train2014_000000443082.jpg" alt="choose text" /></li>
</ul>
</div>
<div id="example-color" class="section level4">
<h4>Example (color)</h4>
<ul>
<li>Question: What color are the boats?</li>
<li>Answers: “blue”, “blue, white”, “blue, brown”, “blue and beige”, “blue green and yellow”, “blue and white”, “blue, white”, “blue and yellow”, “blue and yellow”, “blue”</li>
<li>Image: <img src="images/COCO_train2014_000000443650.jpg" alt="choose color" /></li>
</ul>
</div>
</div>
<div id="subjective" class="section level3">
<h3>Subjective</h3>
<p>Some questions ask for subjective assessments (e.g. whether people are happy, sad, having fun, whether a painting is beautiful, etc.).</p>
<div id="example-2" class="section level4">
<h4>Example</h4>
<ul>
<li>Question: Is he depressed?</li>
<li>Answers: “no”, “yes”, “no”, “no”, “no”, “yes”, “no”, “yes”, “yes”, “yes”</li>
<li>Image: <img src="images/COCO_train2014_000000439550.jpg" alt="subjective" /></li>
</ul>
</div>
</div>
<div id="disagreements-of-meaning" class="section level3">
<h3>Disagreements of meaning</h3>
<p>Sometimes you can pinpoint the exact word that annotators seem to disagree on. If you select this option, you’ll be asked to provide a word or a few words from the question that annotators seem to disagree on.
For example, in the following example, some annotators consider humans to be animals, while others don’t. So for this example, you’d put “animal” into the text box after clicking this option.</p>
<div id="example-3" class="section level4">
<h4>Example</h4>
<ul>
<li>Question: What animal is on the flatbed?</li>
<li>Answers: “none”, “none”, “human”, “none”, “no”, “man”, “people”, “no animal”, “none”,</li>
<li>Image: <img src="images/COCO_train2014_000000443909.jpg" alt="disagree" /></li>
</ul>
</div>
</div>
</div>
<div id="potential-conflicts" class="section level2">
<h2>Potential conflicts</h2>
<div id="invalid-question-vs-low-quality-image" class="section level3">
<h3>Invalid question vs Low quality image</h3>
</div>
<div id="ambiguous-vs-difficult" class="section level3">
<h3>Ambiguous vs Difficult</h3>
</div>
</div>
