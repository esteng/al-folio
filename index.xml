<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Elias Stengel-Eskin</title>
    <link>/</link>
      <atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    <description>Elias Stengel-Eskin</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Fri, 01 Apr 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png</url>
      <title>Elias Stengel-Eskin</title>
      <link>/</link>
    </image>
    
    <item>
      <title>(Invited Talk): Joint Universal Syntactic and Semantic Parsing</title>
      <link>/talk/2022-cornell/</link>
      <pubDate>Fri, 01 Apr 2022 00:00:00 +0000</pubDate>
      <guid>/talk/2022-cornell/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Annotator Instructions</title>
      <link>/misc/uncertainty/</link>
      <pubDate>Wed, 01 Dec 2021 00:00:00 +0000</pubDate>
      <guid>/misc/uncertainty/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;table-of-contents&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;a href=&#34;#introduction&#34;&gt;Introduction&lt;/a&gt;
&lt;ol style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;&lt;a href=&#34;#about-the-interface&#34;&gt;About the interface&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#description-of-categories&#34;&gt;Description of Categories&lt;/a&gt;
&lt;ol style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;&lt;a href=&#34;#low-quality-image&#34;&gt;Low Quality Image&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#invalid-question-or-spam-answer&#34;&gt;Invalid Question/Spam Answer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#difficult-or-time-consuming&#34;&gt;Difficult/Time Consuming&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#synonyms-or-hypernyms&#34;&gt;Synonyms/Hypernyms&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#answer-not-present-or-guessing&#34;&gt;Answer Not Present/Guessing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#ambiguous&#34;&gt;Ambiguous&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#choice-of-many&#34;&gt;Choice of Many&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#disagreements-of-meaning&#34;&gt;Disagreements of Meaning&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;For the follow question about the image, the answers provided may differ. Think of each answer as coming from a different person. Some people might disagree about the answers to the question.&lt;/p&gt;
&lt;p&gt;You will see an image and a question about the image, along with a set of responses from different people. All the responses differ (at least superficially). In some cases, the difference is just a matter of different spellings of the same word or concept. However, in other cases, the disagreement is more pronounced (e.g. half of the annotators said “yes”, the other half said “no”).
Below the image and question, there is a set of labels that identify reasons why annotators may have disagreed. &lt;strong&gt;Please note that you’re not being asked to answer the question itself, or to decide which answer was correct&lt;/strong&gt;. Instead, we would like you to try to infer the reason &lt;strong&gt;why&lt;/strong&gt; people disagreed.&lt;/p&gt;
&lt;p&gt;In this document, descriptions and examples are given for each of these labels.
&lt;strong&gt;Please label with image-question-answer set with the labels, or, if none apply, select “Other” and provide a brief explanation in the text box.&lt;/strong&gt;&lt;/p&gt;
&lt;div id=&#34;about-the-interface&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;About the interface&lt;/h3&gt;
&lt;p&gt;The interface shows the image on the top left, the question and answers on the top right, and the choices on the bottom.
There is an interface on the right side of the image which allows you to zoom in on the image if needed (you are unlikely to need this).
Some choices trigger follow-up questions. These will appear to the right of the existing choices.
With a long image, the choices may be at the bottom of the screen, initially out of view. Please make sure to scroll down to look at all the options before annotating the example.
Each choice has a superscript digit or letter next to it; by pressing that key on your keyboard, you can toggle the choice on or off. Pressing the Control + Enter key combo will submit the task. These shortcuts can help speed up the task.
Note that for a given example, multiple choices can be selected, as in some cases examples will span multiple labels.
&lt;strong&gt;Please try to label each example with as few labels as possible.&lt;/strong&gt; Ideally, each of the examples should receive only one label. We have included the option to annotate with multiple labels, but please use this feature sparingly.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;description-of-categories&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Description of Categories&lt;/h2&gt;
&lt;div id=&#34;low-quality-image&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Low Quality Image&lt;/h3&gt;
&lt;p&gt;Some images are low quality: for example, they may be blurry or dark. This can lead to annotator disagreement, since the annotators might see the image differently.&lt;/p&gt;
&lt;div id=&#34;example&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Example:&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Question: What are the girls holding?&lt;/li&gt;
&lt;li&gt;Answers: “board”, “donut”, “laptop”, “unknown”, “tablet”, “keyboard”, “computer”, “laptop computer”, “laptop”, “laptop”&lt;/li&gt;
&lt;li&gt;Image: &lt;img src=&#34;images/COCO_train2014_000000444945.jpg&#34; alt=&#34;first image&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;invalid-question-or-spam-answer&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Invalid Question or Spam answer&lt;/h3&gt;
&lt;p&gt;This category encompasses two possibilities: invalid questions and spam answers.
Both the questions and answers were generated by annotators, who sometimes produce nonsense.
Some questions are unrelated to the image or generally unanswerable.
Other times, annotators provide nonsense answers to valid questions; this may be deliberate, or maybe they did not understand the question.
We treat these the same way.&lt;/p&gt;
&lt;div id=&#34;example-invalid-question&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Example (Invalid Question):&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Question: what are&lt;/li&gt;
&lt;li&gt;Answers: “lights”, “lamp”, “lamps”, “pillows”, “hotel”&lt;/li&gt;
&lt;li&gt;Image: &lt;img src=&#34;images/COCO_train2014_000000109928.jpg&#34; alt=&#34;second image&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;example-spam-answer&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Example (Spam Answer):&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Question: Is the man reading?&lt;/li&gt;
&lt;li&gt;Answers: “yes”, “yes”, “yes”, “&lt;strong&gt;magazine&lt;/strong&gt;”&lt;/li&gt;
&lt;li&gt;Image: &lt;img src=&#34;images/COCO_train2014_000000441544.jpg&#34; alt=&#34;spam answer&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;difficult-or-time-consuming&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Difficult or Time Consuming&lt;/h3&gt;
&lt;p&gt;Questions can be impossible, very difficult, or time-consuming to answer. For example, the question may ask the annotator to count many small objects, making it very hard to get an exact answer.&lt;/p&gt;
&lt;div id=&#34;example-1&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Example:&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Question: How many cars are there?&lt;/li&gt;
&lt;li&gt;Answers: “2”, “7”, “2”, “1”, “1”, “6”, “6”, “3”, “many”, “4”&lt;/li&gt;
&lt;li&gt;Image: &lt;img src=&#34;images/COCO_train2014_000000445113.jpg&#34; alt=&#34;difficult&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;synonyms-or-hypernyms&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Synonyms or Hypernyms&lt;/h3&gt;
&lt;p&gt;Annotators might differ slightly in how they phrase an answer, or identify objects at different levels of granularity. Crucially, for this label, all the annotations should refer to the &lt;strong&gt;same object or concept&lt;/strong&gt;.&lt;/p&gt;
&lt;div id=&#34;example-synonyms&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Example (synonyms):&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Question: What is the person holding?&lt;/li&gt;
&lt;li&gt;Answers: “tennis racket”, “tennis racket”, “tennis racket”, “racquet”, “racket”, “tennis racket”, “tennis racket”, “racquet”, “racket”, “tennis racket”&lt;/li&gt;
&lt;li&gt;Image: &lt;img src=&#34;images/COCO_train2014_000000442961.jpg&#34; alt=&#34;synonyms&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;example-hypernyms&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Example (hypernyms):&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Question: What sits on the left hand side of the bowl?&lt;/li&gt;
&lt;li&gt;Answers: “container”, “jug”, “container”, “bottle”&lt;/li&gt;
&lt;li&gt;Image: &lt;img src=&#34;images/COCO_train2014_000000438671.jpg&#34; alt=&#34;hypernyms&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;answer-not-present-or-guessing&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Answer not Present or Guessing&lt;/h3&gt;
&lt;p&gt;Questions sometimes are asking for information not visible in the image (e.g. questions about objects partially out of the frame, or not depictable in an image). Annotators will often differ in their answers for such images.
Clicking this option will open another annotation menu to the right, with the following labels:&lt;/p&gt;
&lt;div id=&#34;example-motion&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Example (motion):&lt;/h4&gt;
&lt;p&gt;The question asks about the motion of an object; since we’re dealing with images, this can be hard to infer.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Question: Is the train moving?&lt;/li&gt;
&lt;li&gt;Answers: “no”, “no”, “no”, “no”, “yes”, “no”, “yes”, “yes”, “yes”, “yes”&lt;/li&gt;
&lt;li&gt;Image: &lt;img src=&#34;images/COCO_train2014_000000441034.jpg&#34; alt=&#34;motion&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;example-out-of-view&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Example (out of view):&lt;/h4&gt;
&lt;p&gt;The question asks about an object or event that is out of view of the image&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Question: What is inside the yellow plastic object?&lt;/li&gt;
&lt;li&gt;Answers: “groceries”, “stuff”, “products”, “toiletries”, “stuff”, “food”, “food”, “luggage”,&lt;/li&gt;
&lt;li&gt;Image: &lt;img src=&#34;images/COCO_train2014_000000445462.jpg&#34; alt=&#34;out-of-view&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;example-predicting-the-future&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Example (predicting the future):&lt;/h4&gt;
&lt;p&gt;The question asks about whether something will happen in the future.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Question: Is the woman going to eat it all?&lt;/li&gt;
&lt;li&gt;Answers: “no”, “yes”, “no”, “no”, “no”, “no”, “no”, “yes”, “no”&lt;/li&gt;
&lt;li&gt;Image: &lt;img src=&#34;images/COCO_train2014_000000439576.jpg&#34; alt=&#34;predicting future&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;example-hypothetical&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Example (hypothetical):&lt;/h4&gt;
&lt;p&gt;The question asks whether something hypothetically would happen.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Question: Could passenger be boarding?&lt;/li&gt;
&lt;li&gt;Answers: “yes”, “no”, “no”, “yes”, “yes”, “no”&lt;/li&gt;
&lt;li&gt;Image: &lt;img src=&#34;images/COCO_train2014_000000444210.jpg&#34; alt=&#34;hypothetical&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;example-domain-knowledge&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Example (domain knowledge):&lt;/h4&gt;
&lt;p&gt;The question might be any one of the above (motion, out of view, prediciting the future, hypothetical), but the answers indicate that some people give a certain answer based on domain knowledge, while others might give a different, less informed answer. This happens often with sports.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Question: What trick is he performing?&lt;/li&gt;
&lt;li&gt;Answers: “rail riding”, “ollie”, “skateboard trick”, “rail grinding”, “railslide”, “rail slide”, “grinding”, “slide”, “loop”, “sliding on rail”&lt;/li&gt;
&lt;li&gt;Image: &lt;img src=&#34;images/COCO_train2014_000000044327.jpg&#34; alt=&#34;domain&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There is also an “other” option which will prompt you to provide your own answer.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;ambiguous&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Ambiguous&lt;/h3&gt;
&lt;p&gt;This category is very broad, and may overlap with other categories. At the end of this instruction document are some examples to help distinguish ambiguous from other related categories.
In some cases, the image is ambiguous; in other cases, it is the question. It is also possible for both to be ambiguous.&lt;/p&gt;
&lt;div id=&#34;example-image&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Example (image)&lt;/h4&gt;
&lt;p&gt;This option should be used when an image is visually ambiguous.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Question: How many lamps are on the counter ?&lt;/li&gt;
&lt;li&gt;Answers: “1”, “1”, “2”, “1”, “2”, “2”, “1”&lt;/li&gt;
&lt;li&gt;Image: &lt;img src=&#34;images/COCO_train2014_000000465213.jpg&#34; alt=&#34;visually-ambiguous&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;example-question&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Example (question)&lt;/h4&gt;
&lt;p&gt;This option should be used when a question is linguistically ambiguous.
&lt;strong&gt;This includes questions where annotators could take a different perspective to get different answers (e.g. left vs right)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Question: In which direction is the wave moving?&lt;/li&gt;
&lt;li&gt;Answers: “south”, “forward”, “right”, “forward”, “down”, “right”, “toward beach”, “right”, “left to right”, “left”&lt;/li&gt;
&lt;li&gt;Image: &lt;img src=&#34;images/COCO_train2014_000000440314.jpg&#34; alt=&#34;blah&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;choice-of-many&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Choice of many&lt;/h3&gt;
&lt;p&gt;When annotators are asked to choose one thing from an image and there are many options, they will often choose different ones. This happens frequently with text or colors.&lt;/p&gt;
&lt;div id=&#34;example-text&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Example (text)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Question: What does the boy’s shirt say?&lt;/li&gt;
&lt;li&gt;Answers: “eagles”, “miami eagles legends, all state champions usa”, “america beautiful”, “miami eagles usa”, “m”, “miami eagles”, “miami eagles”&lt;/li&gt;
&lt;li&gt;Image: &lt;img src=&#34;images/COCO_train2014_000000443082.jpg&#34; alt=&#34;choose text&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;example-color&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Example (color)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Question: What color are the boats?&lt;/li&gt;
&lt;li&gt;Answers: “blue”, “blue, white”, “blue, brown”, “blue and beige”, “blue green and yellow”, “blue and white”, “blue, white”, “blue and yellow”, “blue and yellow”, “blue”&lt;/li&gt;
&lt;li&gt;Image: &lt;img src=&#34;images/COCO_train2014_000000443650.jpg&#34; alt=&#34;choose color&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;subjective&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Subjective&lt;/h3&gt;
&lt;p&gt;Some questions ask for subjective assessments (e.g. whether people are happy, sad, having fun, whether a painting is beautiful, etc.).&lt;/p&gt;
&lt;div id=&#34;example-2&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Example&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Question: Is he depressed?&lt;/li&gt;
&lt;li&gt;Answers: “no”, “yes”, “no”, “no”, “no”, “yes”, “no”, “yes”, “yes”, “yes”&lt;/li&gt;
&lt;li&gt;Image: &lt;img src=&#34;images/COCO_train2014_000000439550.jpg&#34; alt=&#34;subjective&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;disagreements-of-meaning&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Disagreements of meaning&lt;/h3&gt;
&lt;p&gt;Sometimes you can pinpoint the exact word that annotators seem to disagree on. If you select this option, you’ll be asked to provide a word or a few words from the question that annotators seem to disagree on.
For example, in the following example, some annotators consider humans to be animals, while others don’t. So for this example, you’d put “animal” into the text box after clicking this option.&lt;/p&gt;
&lt;div id=&#34;example-3&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Example&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Question: What animal is on the flatbed?&lt;/li&gt;
&lt;li&gt;Answers: “none”, “none”, “human”, “none”, “no”, “man”, “people”, “no animal”, “none”,&lt;/li&gt;
&lt;li&gt;Image: &lt;img src=&#34;images/COCO_train2014_000000443909.jpg&#34; alt=&#34;disagree&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;potential-conflicts&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Potential conflicts&lt;/h2&gt;
&lt;div id=&#34;invalid-question-vs-low-quality-image&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Invalid question vs Low quality image&lt;/h3&gt;
&lt;/div&gt;
&lt;div id=&#34;ambiguous-vs-difficult&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Ambiguous vs Difficult&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Calibrating Concepts and Operations: Towards Symbolic Reasoning on Real Images</title>
      <link>/publication/2021-gqa-iccv/</link>
      <pubDate>Sun, 29 Aug 2021 00:00:00 +0000</pubDate>
      <guid>/publication/2021-gqa-iccv/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Guiding Multi-Step Rearrangement Tasks with Natural Language Instructions</title>
      <link>/publication/2021-robots-corl/</link>
      <pubDate>Sun, 29 Aug 2021 00:00:00 +0000</pubDate>
      <guid>/publication/2021-robots-corl/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Iterative Paraphrastic Augmentation with Discriminative Span Alignment</title>
      <link>/publication/2021-paraphrase/</link>
      <pubDate>Tue, 11 May 2021 00:00:00 +0000</pubDate>
      <guid>/publication/2021-paraphrase/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Joint Universal Syntactic and Semantic Parsing</title>
      <link>/publication/2021-decomp-joint/</link>
      <pubDate>Mon, 12 Apr 2021 00:00:00 +0000</pubDate>
      <guid>/publication/2021-decomp-joint/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Human-Model Divergence in the Handling of Vagueness</title>
      <link>/publication/2021-vagueness-scil/</link>
      <pubDate>Wed, 17 Feb 2021 00:00:00 +0000</pubDate>
      <guid>/publication/2021-vagueness-scil/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Human-Model Divergence in the Handling of Vagueness</title>
      <link>/talk/2021-scil/</link>
      <pubDate>Wed, 17 Feb 2021 00:00:00 +0000</pubDate>
      <guid>/talk/2021-scil/</guid>
      <description></description>
    </item>
    
    <item>
      <title>CLSP Seminar Talk: Universal Decompositional Semantic Parsing</title>
      <link>/talk/2020-clsp/</link>
      <pubDate>Fri, 20 Nov 2020 12:00:00 +0000</pubDate>
      <guid>/talk/2020-clsp/</guid>
      <description></description>
    </item>
    
    <item>
      <title>HCI Assignment 2</title>
      <link>/hci/assignment2/</link>
      <pubDate>Tue, 03 Nov 2020 00:00:00 +0000</pubDate>
      <guid>/hci/assignment2/</guid>
      <description>


&lt;div id=&#34;hci-assignment-2-reflections-on-accessiblitiy-and-hostile-road-design-in-baltimore&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;HCI Assignment 2: Reflections on Accessiblitiy and Hostile Road Design in Baltimore&lt;/h1&gt;
&lt;p&gt;New York City is crowded. The traffic is a nightmare. Standing on a corner, you can watch a motley array of vehicles speed pass, from honking taxis to someone pulling three shopping carts piled two stories high with cans. Often, driving is slower than walking. And yet, as bad as it is, it pales in comparison to the behaviour that Baltimore denizens would like to pass off as &amp;quot;driving,&amp;quot; but that would in any other place be classified as attempted manslaughter. If I, as an able-bodied person, feel unwelcome as a pedestrian and biker in this city, then barriers facing those with physical disabilities are staggering. To illustrate these problems, let us focus in on one particular intersection that is likely familiar to those who have spent some time on Homewood Campus: North Calvert and University Parkway.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;satellite.png&#34; /&gt;

&lt;/div&gt;
&lt;p&gt;What could be a standard intersection is turned into an unsafe, rage-inducing nightmare by poor design. I will use this intersection to illustrate some larger problems in the city as a whole, and argue that addressing these problems goes beyond traffic safety.&lt;/p&gt;
&lt;div id=&#34;the-problem&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The problem&lt;/h2&gt;
&lt;p&gt;The following video, taking during rush hour on a weekday, illustrates the following scenario: you&#39;re a pedestrian trying to cross north on the west corner of University and Calvert. You have the light, but an endless stream of drivers turn left off of Calvert onto University block your path. Although you have the right of way, nobody slows down.&lt;/p&gt;
&lt;p&gt;
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/HYklE5K-Rm0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;When this happens, you have several choices:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Take your life into your hands, start walking, stare down the driver in the front and hope that they&#39;re not texting and are willing to stop for you. Whenever I&#39;ve done this, I get the types of bewildered looks from drivers typically reserved for strange occurrences, like a two-ton bison walking across the street. This option requires a good deal of chutzpah (and frustration).&lt;/li&gt;
&lt;li&gt;Wait for a break between the cars and run for it. This is, of course, contingent on there being a break, and furthermore, on your running ability, so this option is inaccessible to a large segment of the population. A segment which is already under-priviledged.&lt;/li&gt;
&lt;li&gt;Wait for the stream to end. Sometimes this means missing the light, especially at rush hour.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Note that option 2 and often option 3 involve breaking the law yourself as a pedestrian, making them further inaccessible to over-policed populations. This problem isn&#39;t confined to this intersection. While overall traffic deaths were down in Baltimore in 2019, pedestrian and bicyclist deaths were up.&lt;a href=&#34;#fn1&#34; class=&#34;footnoteRef&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;hypothesized-causes&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Hypothesized causes&lt;/h2&gt;
&lt;p&gt;It&#39;s very tempting to blame drivers, but it&#39;s also very unlikely that every single driver swining a left onto University between the hours of 4pm and 8pm is a malicious idiot (or one of the more colorful terms I&#39;ve used while executing one of Options 1-3). The intersection is very poorly designed. Firstly, a pedestrian standing on the south-west corner of the intersection is not visible to a driver until they pass the parked vehicles on the west side of Calvert. Even if the pedestrian is visible, the fact that University is so wide and the turn is an obtuse angle means that if their eyes are on the road in front of them, the driver might not see the pedestrian at all.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;satellite_close_annotated.png&#34; alt=&#34;Red arrows indicate driver&amp;#39;s line of sight, red circle indicates pedestrian location on south-west corner. Drivers are unlikely to see the pedestrian.&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;&lt;em&gt;Red arrows indicate driver&#39;s line of sight, red circle indicates pedestrian location on south-west corner. Drivers are unlikely to see the pedestrian.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;This intersection illustrates the larger problem at hand: driving infrastructure has been prioritized over walking and biking infrastructure. This implicitly prioritizes the needs of motorists over everyone else, something that motorists pick up on, leading to a sense of entitlement that is not wholly undeserved. Baltimore drivers should feel entitled; a whole city has been designed and optimized to serve their needs! That feeling of entitlement extends beyond yielding to pedestrians at signals: in my time here, I&#39;ve seen such &amp;quot;creative&amp;quot; driving techniques as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;driving the wrong way down a 3-lane road&lt;/li&gt;
&lt;li&gt;driving on the sidewalk (frequent)&lt;/li&gt;
&lt;li&gt;driving a 4x4 clean over a raised traffic median to execute an illegal U-turn&lt;/li&gt;
&lt;li&gt;countless instances of drivers treating red lights as &amp;quot;stoptional&amp;quot;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Some of these behaviours aren&#39;t just due to culture, but also due to safety concerns. When I moved to Baltimore, a friend who&#39;d been living here for a few years gave me a few tips for driving in Baltimore (especially at night) including&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;know when you&#39;re in an area where you might need to run a light&lt;/li&gt;
&lt;li&gt;don&#39;t pull up to close to the car in front of you at an intersection: you don&#39;t want to be boxed in.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These safety concerns are amplified for residents without the safety of a locked car. I&#39;ve frequently heard friends and neighbors express concern about walking or biking somewhere, even in neighborhoods considered by most to be safe. I will say that these concerns are largely unfounded: most of Baltimore is quite walkable and bikeable. But facts don&#39;t really matter in these situations: it&#39;s the reputation that counts.&lt;/p&gt;
&lt;p&gt;This creates a vicious cycle: people don&#39;t want to walk or bike because it feels unsafe, so they drive. More drivers means more people demanding that the city be designed to meet their needs. More pedestrian-hostile roads mean fewer pedestrians and bikers. Fewer pedestrians and bikers give the city an empty, forelorn feeling, disincentivizing those who would overwise walk. Rinse and repeat.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;proposed-fixes&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Proposed fixes&lt;/h2&gt;
&lt;p&gt;So how can the cycle be broken? Let&#39;s look back at our intersection. Just in this one intersection, here are some changes that could be implemented by, say, a few disgruntled PhD students with some time to spare.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;strong&gt;Give pedestrians a head start&lt;/strong&gt;: there&#39;s a traffic light on Calvert that could be asyncronously timed with the pedestrian light, so that pedestrians have, say, 30 seconds to cross the street before the traffic from Calvert gets to go. This would make the intersection more accessible to those incapable of sprinting across. It would also send a message to drivers by literally prioritizing pedestrians.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Install a red light camera&lt;/strong&gt;: another problem at this intersection is drivers making illegal lefts on red when there&#39;s less traffic on University.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Bottleneck the intersection with a bump-out&lt;/strong&gt;: remove the final two parking spaces on Calvert with a &amp;quot;bump-out&amp;quot;.&lt;a href=&#34;#fn2&#34; class=&#34;footnoteRef&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt; A bump-out is a raised extension of the sidewalk that pushes into the road. It can be covered in low-growing shrubs or thin tall saplings. The effect of a bump-out is two-fold. In removing the parked cars closest to the intersection, it increases pedestrian visibility. It can also be extended into the road itself, creating a bottleneck. A two-lane road becomes a one-lane road, and drivers are forced to slow down, increasing the chance that I can make eye contact with them and hit them with my most searing glare.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Some other changes that could be made around the city include:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;strong&gt;Protected bike lanes&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Lower curbs&lt;/strong&gt;: why on earth are the curbs in this city so high? A high curb is a barrier to anyone in a wheelchair, and forces bicyclists to choose between wiping out and getting hit by a car, instead of safely bailing out onto the sidewalk if, for example, there is a pothole.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Protective bollards&lt;/strong&gt;: implemented in many European cities to prevent vehicular terrorist attacks, concrete bollards would help stop drivers from driving on the sidewalk.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;broader-impacts&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Broader impacts&lt;/h2&gt;
&lt;p&gt;The obvious impacts of these changes are improved pedestrian and bike safety. This means greater accessibility for diverse groups, such as&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;people with physical disabilities&lt;/li&gt;
&lt;li&gt;those who are unable to afford vehicles&lt;/li&gt;
&lt;li&gt;over-policed groups&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;But they might improve other factors as well: for example, an improved and more conscientious driving culture might also result in fewer driver deaths and injuries. Improvements might well extend beyond this: I would argue that increasing the number of pedestrians and bicyclists, and slowing the rate of traffic, offers significant economic upsides. When people drive places, they typically have a destination in mind. Nobody pulls their car over because they saw a cute cafe and want a latte. Pedestrians and bikers see more storefronts, and are more likely to go in and grab a cup of coffee or check out a new clothing shop. Increased pedestrian density would likely also lead to improved safety; each pedestrian is a witness to any potential crimes, reducing the likelihood of any occurring. Finally, walking and biking have been shown to improve not just physical, but also mental health.&lt;a href=&#34;#fn3&#34; class=&#34;footnoteRef&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt; Similarly, increased access to greenspace has been shown to have similar outcomes.&lt;a href=&#34;#fn4&#34; class=&#34;footnoteRef&#34; id=&#34;fnref4&#34;&gt;&lt;sup&gt;4&lt;/sup&gt;&lt;/a&gt; This addresses Baltimore&#39;s safety problem proactively, indirectly tackling the correlates of violent crime.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;&lt;a href=&#34;https://www.baltimoresun.com/maryland/bs-md-traffic-fatalities-20190417-story.html&#34; class=&#34;uri&#34;&gt;https://www.baltimoresun.com/maryland/bs-md-traffic-fatalities-20190417-story.html&lt;/a&gt;&lt;a href=&#34;#fnref1&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;&lt;a href=&#34;https://www.wired.com/2016/10/how-to-design-better-cities/&#34; class=&#34;uri&#34;&gt;https://www.wired.com/2016/10/how-to-design-better-cities/&lt;/a&gt;&lt;a href=&#34;#fnref2&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;&lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1470658/&#34; class=&#34;uri&#34;&gt;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1470658/&lt;/a&gt;&lt;a href=&#34;#fnref3&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn4&#34;&gt;&lt;p&gt;&lt;a href=&#34;https://www.pnas.org/content/116/11/5188&#34; class=&#34;uri&#34;&gt;https://www.pnas.org/content/116/11/5188&lt;/a&gt;&lt;a href=&#34;#fnref4&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Slack For Instructors</title>
      <link>/hci/project1/</link>
      <pubDate>Fri, 16 Oct 2020 00:00:00 +0000</pubDate>
      <guid>/hci/project1/</guid>
      <description>


&lt;div id=&#34;ariel-bao-cameron-franz-elias-stengel-eskin&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Ariel Bao, Cameron Franz, Elias Stengel-Eskin&lt;/h3&gt;
&lt;/div&gt;
&lt;div id=&#34;background&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Background&lt;/h1&gt;
&lt;p&gt;Due to the COVID-19 pandemic, many aspects of life including education have moved to a largely online setting. This has created new challenges but also new opportunities for streamlining and improving educational experiences. The Slack platform is incredibly popular in modern office spaces and offers rapid and efficient communication, we believe that with some minor changes, it could provide and integrated educational environment that enriches student-instructor interactions. In particular, the rapid feedback available through Slack might provide a suitable proxy for face-to-face communication while accommodating individuals facing the myriad additional challenges of teaching and studying from home (e.g. different timezones, unreliable internet, personal responsiblities, etc.).&lt;/p&gt;
&lt;p&gt;In this project, we focus on the perspective of the instructor, as in a course the instructor typically plays a more active role with the students largely acting as consumers. Our product is designed for a modified course structure, which has been adjusted for remote learning. Students are expected to watch pre-recorded lectures on their own time, and there are mandatory 1-hour office-hour-style discussion periods once a week. Each week has two lectures. The course has 3 assignments and 2 group projects.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;contextual-inquiry&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Contextual inquiry&lt;/h1&gt;
&lt;div id=&#34;subject&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Subject&lt;/h3&gt;
&lt;p&gt;The &lt;em&gt;contextual inquiry&lt;/em&gt; was conducted with a student with TA-ing experience who has used Slack in the past, but not extensively. We opted to use a contextual inquiry for our user research, as this best puts us in the shoes of someone using Slack for teaching while concomitantly allowing us to build a better persona of the instructor.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;intents&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Intents&lt;/h3&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Create an assignment and share it with all students 
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/IOaJJO_02zo&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
 
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/vChONkF07zM&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Send each student their graded assignment with feedback 
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/hLidERXSoDY&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
 
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/lhRLNIUDgfo&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Assign students to groups for the group project 
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/Z4GxzMarT2o&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
 
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/dgxGqNcylZY&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Assign each group a topic 
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/bEljMZ2F018&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
 
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/6_hfccsCzlc&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Create a discussion thread for the weekly office hour and send students a required reading for that week’s office hour 
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/i5NKk7XoHIw&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
 
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/SqOs1DMhrb4&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;personas&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Personas&lt;/h2&gt;
&lt;p&gt;Two main personas are Slack users in the use case of remote class instructions: instructors (professors and teaching assistants), and students.&lt;/p&gt;
&lt;p&gt;Though more and more schools and courses start to adopt Slack as a communication channel, many students are not well adapted to using it. Students generally express a preference for email over Slack for long-grown habits. From the students we interviewed, they have also complained about having to jump between different platforms (Blackboard, Slack, email, Gradescope, Messenger, etc.) to check grades, look for announcements, and communicate with teammates.&lt;/p&gt;
&lt;p&gt;Instructors sometimes also distribute information separately from different channels. Since there is no special Slack version designed for course purposes, some instructors also only use Slack for communication, and post documents on other platforms, which further worsens the instructor and student’s inefficiency on unintegrated information.&lt;/p&gt;
&lt;p&gt;After discussion, we decided that instructors’ decisions on the scope and frequency of using Slack for teaching will be the most important factor in deciding how much and how well-versed students use Slack. By targeting the instructor persona, we will enhance the convenience and efficiency of typical tasks instructors perform on Slack, incentive them to use Slack for more course activities, and thus also incentivizing students to use it more.&lt;/p&gt;
&lt;div id=&#34;persona-instructor&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Persona: Instructor&lt;/h3&gt;
&lt;p&gt;Based on our CI and background knowledge, we propose the following persona for an instructor: The instructor has multiple responsibilities, of which teaching is only one. Despite the changes associated with remote learning, the instructor endeavours to provide the best possible experience for their students. Thus, efficiency is of paramount importance to the instructor; they are ready to devote time to their course, but want to minimize the amount of time spent on tedious non-teaching activities. Furthermore, the instructor is cognizant of the different cirumstances under which students are learning this semester. The instructor is familiar with Slack&#39;s interfaces and is computer-literate.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;ideation-and-analysis&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Ideation and Analysis&lt;/h1&gt;
&lt;div id=&#34;channels-were-used-for-groups-and-assignments&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Channels were used for Groups and Assignments&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;SlackExample2.png&#34; alt=&#34;Slack Image&#34; /&gt; &lt;em&gt;A classroom slack environment with relevant areas circled&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;We found that channels (circled in blue) were used for making groups and creating discussion around assignments. To create a channel, the instructor clicks the Add Channel button (green circle). A channel dedicated to sending assignments to students was relatively fast: the instructor simply creates a channel and has it automatically add everyone. Using channels for groups was more tedious. For each group, the instructor needed to click “Add Channel” and type the name of everyone in the group. This means that the instructor would need to &lt;strong&gt;create their groups somewhere else&lt;/strong&gt; (like Excel) and then repeatedly perform copy and pasting or typing, even though all of the names are already in Slack.&lt;/p&gt;
&lt;p&gt;We believe that it should be easier to &lt;strong&gt;automatically populate channels&lt;/strong&gt; with randomly assigned groups in a way that minimizes instructor effort while maximizing flexibility. Furthermore, given the increased number of students who are learning remotely from all over the world, we believe that any changes should natively support grouping students by &lt;strong&gt;timezone&lt;/strong&gt;.&lt;/p&gt;
&lt;div id=&#34;inefficient-communication-and-personal-progress-management&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Inefficient communication and personal progress management&lt;/h3&gt;
&lt;p&gt;Direct messages were used for direct teacher-student communication, such as giving grades and feedback. For each student the instructor would: click on that student, paste a message like “You got a 95%, my feedback is X”, edit that message, and then send the DM. Doing this for each student is obviously tedious, and it does beg a further question: does the instructor have their grades and feedback in some other document (like Excel) and is pasting them over? Or are they going to each student, grading their assignment, and sending messages as they go? In the Excel case it is a lot of copying and pasting to send a DM to every student, and being able to automatically send templated messages from a spreadsheet would be useful. In the grading-as-they-go case, keeping track of who has been graded would be tedious. In our first CI we did not get far enough into the details of how an instructor grades work to answer this question. Yet we can guess from platforms like Gradescope that instructors like to type out their grade and feedback once without having to later copy and paste into some other platform.&lt;/p&gt;
&lt;p&gt;We believe that if Slack is to be used for classroom interactions, there should be an easy-to-use interface for managing and updating coursework.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;finding-information-involved-a-lot-of-browsing-for-students&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Finding information involved a lot of browsing for students&lt;/h3&gt;
&lt;p&gt;We also looked at the Slack classroom from the perspective of a student. In finding out what they need to do, we found that our volunteer student traveled broadly around the Slack classroom. They clicked on multiple channels (the bold ones that indicated unread messages) to look for any relevant new information. They clicked on the channel relevant to their assignment and looked for the original information from the instructor. In general we found that the student, who was using Slack for iOS, was swiping back and forth between the channel menu and the messages area often. They also had to scroll far up in the assignment info to find the pinned information from the instructor.&lt;/p&gt;
&lt;p&gt;In order to minimize the amount of time spent by students traveling between features, we propose adding shortcuts to the interface which allow students to rapidly jump past pinned information.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;SlackDiagram1.png&#34; alt=&#34;Slack Diagram&#34; /&gt; &lt;em&gt;Diagram of how the user performed the various actions during the contextual inquiries&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;prototypes-and-testing&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Prototypes and Testing&lt;/h1&gt;
&lt;p&gt;We developed our prototypes using the &lt;a href=&#34;https://www.figma.com/&#34;&gt;figma&lt;/a&gt; software, building off of Slack templates by &lt;a href=&#34;https://www.figmacrush.com/slack-ui-template-figma/&#34;&gt;figmacrush&lt;/a&gt;. They can be viewed in full &lt;a href=&#34;https://www.figma.com/proto/RmCAbe7ef4TNNY6CcvrjQA/Slack-for-instructors?node-id=71%3A5328&amp;amp;scaling=min-zoom&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;initial-prototype-description&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Initial Prototype Description&lt;/h2&gt;
&lt;div id=&#34;assignment-creation-shortcut&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Assignment creation shortcut&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;featureShowcase.png&#34; alt=&#34;Feature showcase&#34; /&gt; &lt;em&gt;Introducing users to new features is crucial. Here we have a popup that describes the feature, shows where it is, and provides an obvious button to click. Visibility is guaranteed by slightly graying out the rest of the screen. As analyzed previously, participants brought our the problem of tedious manual group creation and the need to rely on other products (eg Excel) for generating lists before transporting to Slack and manually sort students based on their locations, etc. This feature aggregates most group assignment considerations, visualizes final groups, and allows group creation with fewer clicks.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;studentList.png&#34; alt=&#34;student list&#34; /&gt; &lt;em&gt;After clicking the button to create a team, the instructor is presented with this screen. Here the instructor can set their preferences for &lt;em&gt;automatic&lt;/em&gt; group creation — no tedious typing required. Crucially the automatic grouping takes into account time zone, which is a factor that instructors have to consider. If the automatic grouping does not take into account a factor important to the instructor then the instructor will have to adjust the groups later. This can be done later &lt;em&gt;without&lt;/em&gt; more typing.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;timeZones.png&#34; alt=&#34;time zones&#34; /&gt; &lt;em&gt;Here the instructor can see the automatically created groups, and adjust them by dragging names around. Overflow is dealt with by “expand” buttons, though scrolling would also work&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;congrats.png&#34; alt=&#34;congrats&#34; /&gt; &lt;em&gt;The nice animation played here is intended to make the user feel good about using the new feature, although we acknowledge that the actual experience of using the feature will be the main determiner of whether they use it again.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;team-management-dashboard&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Team management dashboard&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;todoList.png&#34; alt=&#34;todo list&#34; /&gt; &lt;em&gt;This is a different feature, also accessible from the main slack sidebar. Here the instructor can find their schedule for things they need to do related to the groups and the assignments, along with the scheduled time and estimated duration based on manual input or estimation from past activities. Submission statistics are also shown for assignments. Ideally grading would also be possible within the interface somewhere, as having to download files or copy and paste is troublesome. But we decide not to do this for now because there is a significant preference and strong habit for existing platforms like Gradescope or Blackboard. Therefore we decided to improve Slack only based on its core functionality, communication. The assignment statistics, which drop down after clicking the little plus, also lead to the ability to schedule reminders for students.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;scheduledMeeting.png&#34; alt=&#34;scheduled meeting&#34; /&gt; &lt;em&gt;Here the instructor can schedule a reminder about the assignment to be sent to students at a specific time. We separate date and time so that there’s not a single date picker switching between calendar and clock.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;scrolling-to-pinned-messages&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Scrolling to pinned messages&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;scroll0.png&#34; alt=&#34;scrolling0&#34; /&gt; &lt;em&gt;Here we provide an interface for the student to quickly find information from their instructor. Clicking on the (i) in the top right will immediately scroll the student to the informational post from the instructor, and clicking the calendar icon will scroll the user back to the most recent messages.&lt;/em&gt; &lt;img src=&#34;scroll1.png&#34; alt=&#34;scrolling1&#34; /&gt; &lt;em&gt;Immediately we see the instructor’s pinned message. This works especially well as more messages are added and scrolling becomes difficult, and where there are multiple pinned messages, in which case there will be more than one (i) marks on the right&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;usability-evaluation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Usability Evaluation&lt;/h2&gt;
&lt;p&gt;For each feature, we conducted &lt;strong&gt;formative&lt;/strong&gt; usability tests with a different subject than was used in the CI. The subject for usability testing is an experienced teacher who currently teaches at the middle and high-school level, and is familiar with teaching in a remote-learning environment. The goals of the first evaluation are to assess the usability of the prototypes with respect to the CI, and to identify any shortcomings to address in further rounds of prototyping. The participant was told that she would be asked to perform a number of tasks on a new software, and that she should do her best and to think out loud. After testing, the subject was debriefed.&lt;/p&gt;
&lt;div id=&#34;managing-assignments&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Managing assignments&lt;/h3&gt;
&lt;p&gt;
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/PQ4E8ytYptc&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;creating-groups&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Creating groups&lt;/h3&gt;
&lt;p&gt;
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/BJBonA0pb0A&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;scrolling-to-pinned-messages-1&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Scrolling to pinned messages&lt;/h3&gt;
&lt;p&gt;
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/IUXRO_3EehQ&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;second-round-ideation-and-prototyping&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Second-round Ideation and Prototyping&lt;/h2&gt;
&lt;p&gt;In the first round of prototype testing, users took the longest time on the second feature (dashboard) and provided feedback that it is the least intuitive to use. They have commented that they preferred customized reminder messages since the content might be different, and easier management of grading events. This feature was added and a final round of &lt;strong&gt;summative&lt;/strong&gt; testing was performed.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;additional0.png&#34; alt=&#34;additional0&#34; /&gt; &lt;em&gt;On the dashboard, we have added two buttons to allow users to add grading activities to their to-do list with suggested times with one click (see lower red box).&lt;/em&gt; &lt;img src=&#34;additional1.png&#34; alt=&#34;additional1&#34; /&gt; &lt;em&gt;Once clicked, the new event will be incorporated to their tasks, with suggested time lengths (based on similar past activities) and documents (can be downloaded by clicking the materials).&lt;/em&gt; &lt;img src=&#34;additional2.png&#34; alt=&#34;additional2&#34; /&gt; &lt;em&gt;From the dashboard, if the instructor clicks the message icon and enter the page to schedule a reminder, they can now customize the message, time, and adjusts the suggested recipient list. After sending the reminder, the system provides feedback to tell them it is sent successfully.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;summative-ux-evaluation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Summative UX evaluation&lt;/h1&gt;
&lt;p&gt;We conducted a final summative evaluation using the same subject as the prototyping evaluation. While this is not ideal, the pool of potential subjects is limited due to social distance regulations. The user was encouraged to talk through tasks out loud, and told that they were not being evaluated but that the evaluation was of the software. They were also expressly encouraged to point out problems. The user was briefed on the purpose of the new product; we recorded their video footage and analyzed their reactions, and then debriefed them.&lt;/p&gt;
&lt;p&gt;
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/jF6vhUzolAk&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
 &lt;em&gt;The user displayed a far greater facility with the tasks than the user recorded during the CI, who had more instruction.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;We additionally asked them to evaluate their trial and satisfaction with self-reported scores in Likert scales and post-trial interviews. In analysis, we used a range of metrics to measure the success of the product. In terms of efficiency, the user speed improved noticeably. In the video recording, we observed that user did not make any error or have difficulty in task completion for our prototypes. In the interview, the user expressed a positive impression of the features, and said they would prefer the new version over the existing ones as TAs.&lt;/p&gt;
&lt;p&gt;In addition to these observations, we conducted a &lt;strong&gt;user experience evaluation&lt;/strong&gt; using a &lt;strong&gt;Likert scale&lt;/strong&gt; questionnaire. This format of post-hoc evaluation allows us to gain deeper insights into the usability of the product and its general impression on the subject after giving them some time to reflect. The questionnaire is available &lt;a href=&#34;https://docs.google.com/forms/d/e/1FAIpQLSfmkVK9W8FfRwnmG3zhlREp0g39B3Zl27Wjh4ecI2MDOiK7xQ/viewform?usp=sf_link&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;survey-results&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Survey results&lt;/h3&gt;
&lt;p&gt;The average score for questions was 4.6/5, with 5 being &amp;quot;strongly agree&amp;quot; and 1 being &amp;quot;strongly disagree.&amp;quot; All questions were positive, so we take this as a good sign that our product was easy to use. The following statements received ratings below 5/5: - &amp;quot;The assignment management interface was easy to find&amp;quot; - &amp;quot;It was clear how to send a reminder to students who hadn&#39;t completed the assignment&amp;quot; - &amp;quot;The function to create an assignment was easy to find&amp;quot; - &amp;quot;It was easy to scroll to a pinned message&amp;quot;&lt;/p&gt;
&lt;p&gt;These represent directions for further improvements.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusions&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Conclusions&lt;/h1&gt;
&lt;p&gt;We have presented a number of features for developing Slack into a standalone platform for teaching courses remotely. We believe that our features touch on many of the issues that were observed in the CI portion. Specifically, we have opted to focus on creating and managing assignments and groups, which is integral to the teaching process, especially as remote classes tend to prefer assignments over exams. Some of the strengths of our approach include our high-fidelity prototypes, the attention to detail in our assignment creation interface especially with respect to creating an equitable learning environment for those learning from other timezones, and our multiple iterations of prototyping and evaluation. Limitations include increased reliance on a single platform, which may make classes more uniform and less flexible.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>HCI Assignment 1</title>
      <link>/hci/assignment1/</link>
      <pubDate>Sat, 10 Oct 2020 00:00:00 +0000</pubDate>
      <guid>/hci/assignment1/</guid>
      <description>


&lt;div id=&#34;hci-assignment-1-improving-basic-functionality-of-myjhu&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;HCI Assignment 1: Improving basic functionality of myJHU&lt;/h1&gt;
&lt;p&gt;Graduate students at JHU are faced with a unique challenge of being both students and employees. This means navigating both the standard student-facing sites for registering for classes and checking grades, like SIS and Blackboard, but also employee interfaces such as ESS. Many of these interfaces are available throught the myJHU portal, but learning how to efficiently use the portal takes time. If there&#39;s one thing graduate students don&#39;t have, it&#39;s time to waste figuring out where to find different features in myJHU. While we agree that myJHU provides a valuable service as an aggregator and portal for the variety of services available to graduate students, the interface itself can be clunky and difficult to use. In this assignment, we will endeavour to redesign the interface, optimizing for customizability and speed.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;contextual-inquiry&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Contextual inquiry&lt;/h1&gt;
&lt;p&gt;To this end, we performed a contextual inquiry to determine which interfaces were most in need of a redesign, and how actual users interact with myJHU.&lt;/p&gt;
&lt;div id=&#34;subject&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Subject&lt;/h2&gt;
&lt;p&gt;For the purposes of this assignment, rather than recruiting a JHU graduate student, whose experience is colored by having used the interface many times before, we opted to recruit a non-JHU student who would act as a proxy for a brand new JHU graduate student using the interface for the first time.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;intents&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Intents&lt;/h2&gt;
&lt;p&gt;Since myJHU is a fairly well-designed page to begin with, we opted to test more intents and narrow down what we would change later on, based on what we saw in our contextual inquiry. These intents were:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Change profile name&lt;/li&gt;
&lt;li&gt;Find a book in the library&lt;/li&gt;
&lt;li&gt;Find Concur system for travel reimbursements&lt;/li&gt;
&lt;li&gt;Change what you see upon login&lt;/li&gt;
&lt;li&gt;Check email&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Based on our inquiry, we opted to further analyze and re-design the page for intents 1, 3, and 4.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;contextual-inquiry-recording&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Contextual inquiry recording&lt;/h2&gt;
&lt;p&gt;
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/t-T2UdpU3hI&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;intent-1-change-profile-name&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Intent 1: Change profile name&lt;/h2&gt;
&lt;p&gt;Often, new students are assigned a profile with their full legal name, but have a different name that they go by. The following shows the sequential model of our subject attempting to change her name in myJHU:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;intent1.png&#34; alt=&#34;&#34; width=&#34;700&#34;/&gt;&lt;/p&gt;
&lt;div id=&#34;results&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Results&lt;/h3&gt;
&lt;p&gt;While the subject was able to find the functions to change the profile easily enough, the save button was all the way at the bottom and took time to find. Another time-waster was two-factor authetication, but for security reasons, this understandably cannot be removed.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;intent-2-find-concur&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Intent 2: Find Concur&lt;/h2&gt;
&lt;p&gt;Concur is only one of the services available to grad students through myJHU, which we use as a proxy for finding services in general.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;intent2.png&#34; alt=&#34;&#34; width=&#34;700&#34;/&gt;&lt;/p&gt;
&lt;div id=&#34;results-1&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Results&lt;/h3&gt;
&lt;p&gt;Concur is buried under the &amp;quot;Travel&amp;quot; option in the sidebar, which the subject had to spend some time visually searching for on the screen. Given just the name (not knowing it is used for travel) it would be very difficult to find.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;intent-3-customize-layout&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Intent 3: Customize Layout&lt;/h2&gt;
&lt;p&gt;The front page of myJHU has news and alerts about various topics at JHU and is spread out over a large area. Students should be able to customize what they see based on what they value.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;intent3.png&#34; alt=&#34;&#34; width=&#34;700&#34;/&gt;&lt;/p&gt;
&lt;div id=&#34;results-2&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Results&lt;/h3&gt;
&lt;p&gt;This turned out to be an impossible task. The subject first went down an incorrect path, assuming that the customization would be part of myProfile. After that, the subject tried to use the &amp;quot;configure&amp;quot; option, which only changes the sidebar. Finally, the subject gave up.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;redesign&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Redesign&lt;/h1&gt;
&lt;p&gt;To address the breakdowns in the previous section, we propose a new, more compact site designed in &lt;a href=&#34;https://gomockingbird.com/&#34;&gt;Mockingbird&lt;/a&gt;:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;main.png&#34; alt=&#34;&#34; width=&#34;500&#34;/&gt;&lt;/p&gt;
&lt;div id=&#34;intent-1-profile-changes&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Intent 1: Profile changes&lt;/h3&gt;
&lt;p&gt;We add a quick-link to change the profile directly under the profile picture. This opens a pop-out menu with the options of fields to change in the profile. &lt;img src=&#34;customize1.png&#34; alt=&#34;&#34; width=&#34;500&#34;/&gt;&lt;/p&gt;
&lt;p&gt;Opening one of these menus changes the content of the pop-out to a list of editable fields. Contents can be discarded with the close button or saved with the large &amp;quot;confirm&amp;quot; button. &lt;img src=&#34;customize2.png&#34; alt=&#34;&#34; width=&#34;500&#34;/&gt;&lt;/p&gt;
&lt;p&gt;These popups allow the user to stay on the same page while updating their information, and update only small parts of their info at a time. The small size of the interface places the &amp;quot;confirm&amp;quot; directly in the subject&#39;s view, where before it required a large amount of scrolling to get to.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;intent-2-open-concur&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Intent 2: Open Concur&lt;/h3&gt;
&lt;p&gt;Rather than forcing the user to use the sidebar, we include a large searchar which can be quickly accessed. As the user types, results begin to be filtered in a quick-search style, until only the top result remains.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;searchbar1.png&#34; alt=&#34;&#34; width=&#34;500&#34;/&gt;&lt;/p&gt;
&lt;p&gt;This interface cuts down on time wasted scrolling over the sidebar and attempting to deduce under which heading different services are located.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;intent-3-customize&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Intent 3: Customize&lt;/h3&gt;
&lt;p&gt;Rather than being spread out and taking up more than the screen, the news and info on the homepage is consolidated into multiple tabs, grouped by topic. This allows for faster access to important information, such as COVID19 updates. The tabs also provide an intuitive interface for customization that everyone is familiar with. Each tab has a close button.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;customize1.png&#34; alt=&#34;&#34; width=&#34;500&#34;/&gt;&lt;/p&gt;
&lt;p&gt;Pressing the close button opens a small prompt which asks the user whether they want to close the window just for the duration of their session, or make their change permanent.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;customize2.png&#34; alt=&#34;&#34; width=&#34;500&#34;/&gt;&lt;/p&gt;
&lt;p&gt;This change allows the user to customize the homepage and re-order what they see based on what they care about. It also makes it obvious how to customize the page, which was unclear before.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;evaluation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Evaluation&lt;/h2&gt;
&lt;p&gt;In the final evaluation, we see that each task took much less time and was more intuitive than before.&lt;/p&gt;
&lt;p&gt;
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/TFyRLlrI6do&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Universal Decompositional Semantic Parsing</title>
      <link>/talk/2020-acl/</link>
      <pubDate>Wed, 08 Jul 2020 13:00:00 +0000</pubDate>
      <guid>/talk/2020-acl/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Exploring fine-grained semantic inferences cross-lingually</title>
      <link>/post/2020-decomp-xlingual/</link>
      <pubDate>Wed, 24 Jun 2020 00:00:00 +0000</pubDate>
      <guid>/post/2020-decomp-xlingual/</guid>
      <description>


&lt;p&gt;Consider the following two scenarios:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Derek was over for dinner at Lisa&#39;s house. After dinner, he offered to do the dishes, but as he was picking up one of the plates his grip slipped and he dropped it. Later, when telling her friend about the night, Lisa said, &amp;quot;Derek broke the plate.&amp;quot;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Derek was over for dinner at Lisa&#39;s house. Lisa claimed that she bought special &amp;quot;unbreakable&amp;quot; plates and challenged Derek to break one. He promptly smacked the plate against the edge of the counter, and broke it. Later, when telling her friend about the night, Lisa said, &amp;quot;Derek broke the plate.&amp;quot;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;1&lt;/th&gt;
&lt;th&gt;2&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;img src=&#34;accident.jpg&#34; alt=&#34;Derek broke the plate accidentally&#34; width=&#34;300&#34;/&gt;&lt;/td&gt;
&lt;td&gt;&lt;img src=&#34;purpose.jpg&#34; alt=&#34;Derek broke the plate on purpose&#34; width=&#34;300&#34;/&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Both times, the statement &amp;quot;Derek broke the plate&amp;quot; remains unchanged. But based on the different scenarios, we as readers draw very different conclusions. Evidence suggests that even toddlers are able to draw inferences about intentionality and volition &lt;span class=&#34;citation&#34;&gt;(Vaish, Carpenter, and Tomasello 2010)&lt;/span&gt;.&lt;a href=&#34;#fn1&#34; class=&#34;footnoteRef&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; Inferences like that in (2), Derek meant to break the plate, while in (1) it was an accident. Furthermore, different scenarios might evoke different levels of volition; we could easily imagine a range of set-ups where Derek is more or less volitional, between the two extremes laid out above. We can also draw a much broader range of inferences from these sentences; for example, we know that Derek is sentient while the plate is not, and that the plate physically changed during the process, but Derek probably wasn&#39;t. We know that the plate probably doesn&#39;t exist anymore, but Derek does. The list goes on...&lt;/p&gt;
&lt;p&gt;This raises a few key questions: how is it that identical sentences can evoke a range of different inferences? What kinds of inferences do we draw from language? What other hidden knowledge is lying just under the surface of the language we speak?&lt;/p&gt;
&lt;p&gt;A rich array of work has looked at these questions, including &lt;span class=&#34;citation&#34;&gt;Dowty (1991)&lt;/span&gt;, who introduced a number of inferences, including &amp;quot;volition&amp;quot;, &amp;quot;awareness&amp;quot;, &amp;quot;sentience&amp;quot;, &amp;quot;change of state&amp;quot;, and &amp;quot;existed before/during/after&amp;quot;. From there, &lt;span class=&#34;citation&#34;&gt;D. Reisinger et al. (2015)&lt;/span&gt;, &lt;span class=&#34;citation&#34;&gt;White et al. (2016)&lt;/span&gt;, &lt;span class=&#34;citation&#34;&gt;Govindarajan, Van Durme, and White (2019)&lt;/span&gt;, and &lt;span class=&#34;citation&#34;&gt;Vashishtha, Van Durme, and White (2019)&lt;/span&gt; annotated a corpus of English sentences these properties (among others) and began modeling them. I myself joined this effort fairly late, contributing to &lt;span class=&#34;citation&#34;&gt;White et al. (2019)&lt;/span&gt;, which consolidated annotations from across these works into one dataset, the Universal Decompositional Semantics Dataset, or &lt;a href=&#34;http://decomp.io&#34;&gt;UDSv1.0&lt;/a&gt;. My main contribution to this line of work has been working on a parsing model, which learns to automatically extract these inferences from text &lt;span class=&#34;citation&#34;&gt;(Stengel-Eskin et al. 2020)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;By way of starting, I&#39;ll try to summarize the different types of annotations in the dataset. The dataset gives each property a score from -3 to 3, with 3 being &amp;quot;very likely&amp;quot; and -3 being &amp;quot;very unlikely.&amp;quot; The words the annotation applies to are given in bold.&lt;/p&gt;
&lt;table&gt;
&lt;colgroup&gt;
&lt;col width=&#34;13%&#34; /&gt;
&lt;col width=&#34;39%&#34; /&gt;
&lt;col width=&#34;46%&#34; /&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;Annotation&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;th&gt;Examples&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;strong&gt;Factuality&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;Factuality inferences represent how likely (or unlikely) a listener thinks a scenario that is to have occurred.&lt;/td&gt;
&lt;td&gt;Jo &lt;strong&gt;left&lt;/strong&gt; (3), Jo didn’t &lt;strong&gt;leave&lt;/strong&gt; (-3), Jo thought that Cole had &lt;strong&gt;left&lt;/strong&gt; (-1)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;&lt;strong&gt;Genericity&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;Genericity refers to inferences about the generality of events or event participants&lt;/td&gt;
&lt;td&gt;&lt;em&gt;Ex. property: genericity-predicate-particular&lt;/em&gt;: Amy &lt;strong&gt;ate&lt;/strong&gt; oats for breakfast today (3), Amy &lt;strong&gt;ate&lt;/strong&gt; oats for breakfast every day (-3)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;strong&gt;Time&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;Temporal inferences are inferences about how long events might take&lt;/td&gt;
&lt;td&gt;&lt;em&gt;Ex. property: time-duration-minutes&lt;/em&gt;: Tom &lt;strong&gt;left&lt;/strong&gt; (-3), Tom was &lt;strong&gt;singing&lt;/strong&gt; (3)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;&lt;strong&gt;Word Sense&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;Words can have different senses/supersenses (e.g. &lt;em&gt;bank&lt;/em&gt; as a place to keep money (phyiscal location) vs. the &lt;em&gt;bank&lt;/em&gt; of a river, (geographical feature)). These sense can apply to differing degrees.&lt;/td&gt;
&lt;td&gt;&lt;em&gt;Ex. property: &amp;quot;person&amp;quot; supersense&lt;/em&gt; Sandy led &lt;strong&gt;Rufus&lt;/strong&gt; by a leash (-3), &lt;strong&gt;Sandy&lt;/strong&gt; led Rufus by a leash (3)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;strong&gt;Semantic proto-roles&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;SPR properties (introduced by &lt;span class=&#34;citation&#34;&gt;Dowty (1991)&lt;/span&gt;) capture properties typically associated with either agents (the person/thing doing the acting in a sitation) and patients (the person/thing that&#39;s being acted upon), like awareness and volition (agent properties) or change of state and being created/destroyed (patient properties)&lt;/td&gt;
&lt;td&gt;&lt;em&gt;Ex. property: volition&lt;/em&gt; &lt;strong&gt;Derek&lt;/strong&gt; broke his arm (-3), &lt;strong&gt;Derek&lt;/strong&gt; broke the wishbone (3) &lt;/br&gt; &lt;em&gt;Ex. property: was used&lt;/em&gt; The fragile vase was shipped with &lt;strong&gt;bubble-wrap&lt;/strong&gt; (3), The fragile vase was shipped with &lt;strong&gt;haste&lt;/strong&gt; (-3)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;div id=&#34;excavation-via-other-languages&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Excavation via other languages&lt;/h2&gt;
&lt;p&gt;When we look at these questions from one linguistic lens alone, we get an impoverished view. Some inferences will present themselves readily, while others will be purely contextual. For example from the English point of view, information on when an event happened is often presented explicitly in the tense of the verb; in another language (such as Mandarin) this information might need to be inferred from context, much like how Derek&#39;s level volition in breaking the plate in English needs to be inferred.&lt;/p&gt;
&lt;p&gt;Other languages offer different lenses through which to view these semantic inferences by varying what they make explicit and what is kept below the surface. Think of semantics as a lost city or desert ruin, with different languages acting as different winds, shifting the surface-level sand to uncover different aspects of the same semantic structure.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;back-to-derek-and-the-plate&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Back to Derek and the plate&lt;/h2&gt;
&lt;p&gt;Let&#39;s revisit Derek, but this time in a different linguistic setting -- say, Mexico City. Where in English, we&#39;d use the same construction in both scenarios (volitional and non-volitional), in Spanish, we&#39;d probably use a different construction. In scenarios (1) and (2), we&#39;d say something like&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;&lt;em&gt;Spanish&lt;/em&gt;&lt;/th&gt;
&lt;th&gt;Se&lt;/th&gt;
&lt;th&gt;le&lt;/th&gt;
&lt;th&gt;rompió&lt;/th&gt;
&lt;th&gt;el plato&lt;/th&gt;
&lt;th&gt;a&lt;/th&gt;
&lt;th&gt;Derek&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;em&gt;Direct English gloss&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;Itself&lt;/td&gt;
&lt;td&gt;to him&lt;/td&gt;
&lt;td&gt;broke&lt;/td&gt;
&lt;td&gt;the plate&lt;/td&gt;
&lt;td&gt;to&lt;/td&gt;
&lt;td&gt;Derek&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;&lt;em&gt;Rough English gloss&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;The&lt;/td&gt;
&lt;td&gt;plate&lt;/td&gt;
&lt;td&gt;broke&lt;/td&gt;
&lt;td&gt;itself&lt;/td&gt;
&lt;td&gt;to&lt;/td&gt;
&lt;td&gt;Derek&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;em&gt;English translation&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;Derek&lt;/td&gt;
&lt;td&gt;broke&lt;/td&gt;
&lt;td&gt;the plate&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;&lt;/li&gt;
&lt;li&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;&lt;em&gt;Spanish&lt;/em&gt;&lt;/th&gt;
&lt;th&gt;Derek&lt;/th&gt;
&lt;th&gt;rompió&lt;/th&gt;
&lt;th&gt;el plato&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;em&gt;En. gloss&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;Derek&lt;/td&gt;
&lt;td&gt;broke&lt;/td&gt;
&lt;td&gt;the plate&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;&lt;em&gt;En. translation&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;Derek&lt;/td&gt;
&lt;td&gt;broke&lt;/td&gt;
&lt;td&gt;the plate&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Both can translate to &amp;quot;Derek broke the plate&amp;quot; in English, but the first utterance indicates that it was an accident. A direct gloss of each sentence is immediately below the example. Funnily enough, the direct gloss here looks a lot like what we might find in German!&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;&lt;em&gt;German&lt;/em&gt;&lt;/th&gt;
&lt;th&gt;Der&lt;/th&gt;
&lt;th&gt;Teller&lt;/th&gt;
&lt;th&gt;ist&lt;/th&gt;
&lt;th&gt;dem&lt;/th&gt;
&lt;th&gt;Derek&lt;/th&gt;
&lt;th&gt;zerbrochen&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;em&gt;En. gloss&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;The-NOM&lt;/td&gt;
&lt;td&gt;plate-NOM&lt;/td&gt;
&lt;td&gt;is-AUX&lt;/td&gt;
&lt;td&gt;the-DAT&lt;/td&gt;
&lt;td&gt;Derek-DAT&lt;/td&gt;
&lt;td&gt;broken&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;&lt;em&gt;Rough En. gloss&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;The&lt;/td&gt;
&lt;td&gt;plate&lt;/td&gt;
&lt;td&gt;broke&lt;/td&gt;
&lt;td&gt;to&lt;/td&gt;
&lt;td&gt;Derek&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;em&gt;En. translation&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;Derek&lt;/td&gt;
&lt;td&gt;broke&lt;/td&gt;
&lt;td&gt;the&lt;/td&gt;
&lt;td&gt;plate&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;&lt;/li&gt;
&lt;li&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;Derek&lt;/th&gt;
&lt;th&gt;hat&lt;/th&gt;
&lt;th&gt;den&lt;/th&gt;
&lt;th&gt;Teller&lt;/th&gt;
&lt;th&gt;zerbrochen.&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Derek&lt;/td&gt;
&lt;td&gt;has&lt;/td&gt;
&lt;td&gt;the-ACC&lt;/td&gt;
&lt;td&gt;plate-ACC&lt;/td&gt;
&lt;td&gt;broken&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;Derek&lt;/td&gt;
&lt;td&gt;broke&lt;/td&gt;
&lt;td&gt;the&lt;/td&gt;
&lt;td&gt;plate&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;#fn2&#34; class=&#34;footnoteRef&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;So looking at two other languages tells us that while English doesn&#39;t necessarily make the distinction between volitional and non-volitional plate breaking (at least in the active voice), other languages do!&lt;a href=&#34;#fn3&#34; class=&#34;footnoteRef&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;what-about-some-other-inferences&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;What about some other inferences&lt;/h2&gt;
&lt;p&gt;Tired of Derek and his plates? Me too. Why not take a step up the linguistic family tree from Spanish and look at its parent, Latin. Latin is a fantastic language for exploring these kinds of inferences for a few reasons. The first is that its a morphologically rich language -- many of the grammatical relations which are encoded by word position in other languages (e.g. subject, predicate, and object in English) are encoded directly on the words. This means that word order is much less important. It also means that wealth of semantic information is encoded in the morphology of a word.&lt;/p&gt;
&lt;p&gt;Another reason Latin is great for looking at these inferences is the way it&#39;s taught. Nouns (and their corresponding adjectives) have cases in Latin, which are different endings to the same stem (much like how verbs in English have different endings for different tenses/moods/persons). The cases are nominative, genitive, dative, accusative, ablative, and vocative (and sometimes locative), all with different uses. To help students remember which cases are used when, the cases come with handy names that are taught in textbooks, like &amp;quot;&lt;em&gt;the ablative of agent&lt;/em&gt;&amp;quot; or &amp;quot;&lt;em&gt;the dative of reference.&lt;/em&gt;&amp;quot; We can match some of these handy mnemonics directly to certain inferences described in &lt;span class=&#34;citation&#34;&gt;Dowty (1991)&lt;/span&gt;. For example, the &amp;quot;was used&amp;quot; property fits well with the &lt;em&gt;ablative of instrument&lt;/em&gt;, where an ablative ending tells us something was used as a tool in an action, i.e.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;Caesar&lt;/th&gt;
&lt;th&gt;gladiis&lt;/th&gt;
&lt;th&gt;occidus&lt;/th&gt;
&lt;th&gt;est&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Caesar-NOM&lt;/td&gt;
&lt;td&gt;swords-ABL&lt;/td&gt;
&lt;td&gt;killed-NOM&lt;/td&gt;
&lt;td&gt;is-AUX&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;Caesar&lt;/td&gt;
&lt;td&gt;with swords&lt;/td&gt;
&lt;td&gt;killed&lt;/td&gt;
&lt;td&gt;was&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Caesare&lt;/td&gt;
&lt;td&gt;was&lt;/td&gt;
&lt;td&gt;killed&lt;/td&gt;
&lt;td&gt;with swords&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Similarly, Dowty&#39;s &amp;quot;was for the benefit of&amp;quot; property demands nothing less than the dative, in this case often known as the &lt;em&gt;dative of advantage/disadvantage&lt;/em&gt;. &lt;em&gt;Cui bono&lt;/em&gt; is a famous example of this.&lt;a href=&#34;#fn4&#34; class=&#34;footnoteRef&#34; id=&#34;fnref4&#34;&gt;&lt;sup&gt;4&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;These mnemonic devices not only help students learn Latin, but also help to expose some of the underlying semantic features of the language.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;genericity&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Genericity&lt;/h2&gt;
&lt;p&gt;Genericity inferences pertain to how particular or abstract a predicate or argument is. For example, it&#39;s clear that &amp;quot;dogs&amp;quot; in &amp;quot;My uncle Roger&#39;s dogs Fifi and Fido&amp;quot; is different from &amp;quot;dogs&amp;quot; in &amp;quot;my brother is afraid of dogs&amp;quot;, in that the first &amp;quot;dogs&amp;quot; is very particular, while the second one applies to more of a natural kind. Similarly, predicates can be more or less particular or general. Consider:&lt;/p&gt;
&lt;ol start=&#34;3&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Marie ate oatmeal for breakfast every day.&lt;/li&gt;
&lt;li&gt;Marie ate oatmeal for breakfast yesterday.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The &amp;quot;ate&amp;quot; in (3) is different from the &amp;quot;ate&amp;quot; in (4), which encompases a broader range of instances of an &amp;quot;eating&amp;quot; event. French makes this distinction quite clear on the surface level:&lt;/p&gt;
&lt;ol start=&#34;3&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;Marie&lt;/th&gt;
&lt;th&gt;a&lt;/th&gt;
&lt;th&gt;mangé&lt;/th&gt;
&lt;th&gt;du&lt;/th&gt;
&lt;th&gt;gruau&lt;/th&gt;
&lt;th&gt;pour&lt;/th&gt;
&lt;th&gt;son&lt;/th&gt;
&lt;th&gt;petit&lt;/th&gt;
&lt;th&gt;déjeuner&lt;/th&gt;
&lt;th&gt;hier&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Marie&lt;/td&gt;
&lt;td&gt;has&lt;/td&gt;
&lt;td&gt;eaten&lt;/td&gt;
&lt;td&gt;of the&lt;/td&gt;
&lt;td&gt;oatmeal&lt;/td&gt;
&lt;td&gt;for&lt;/td&gt;
&lt;td&gt;her&lt;/td&gt;
&lt;td&gt;small&lt;/td&gt;
&lt;td&gt;lunch&lt;/td&gt;
&lt;td&gt;yesterday&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;Marie&lt;/td&gt;
&lt;td&gt;ate&lt;/td&gt;
&lt;td&gt;oatmeal&lt;/td&gt;
&lt;td&gt;for&lt;/td&gt;
&lt;td&gt;breakfast&lt;/td&gt;
&lt;td&gt;yesteray&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;&lt;/li&gt;
&lt;li&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;Marie&lt;/th&gt;
&lt;th&gt;mangeait&lt;/th&gt;
&lt;th&gt;du&lt;/th&gt;
&lt;th&gt;gruau&lt;/th&gt;
&lt;th&gt;pour&lt;/th&gt;
&lt;th&gt;son&lt;/th&gt;
&lt;th&gt;petit&lt;/th&gt;
&lt;th&gt;déjeuner&lt;/th&gt;
&lt;th&gt;tous&lt;/th&gt;
&lt;th&gt;les&lt;/th&gt;
&lt;th&gt;jours&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Marie&lt;/td&gt;
&lt;td&gt;ate-PROG&lt;/td&gt;
&lt;td&gt;of the&lt;/td&gt;
&lt;td&gt;oatmeal&lt;/td&gt;
&lt;td&gt;for&lt;/td&gt;
&lt;td&gt;her&lt;/td&gt;
&lt;td&gt;small&lt;/td&gt;
&lt;td&gt;lunch&lt;/td&gt;
&lt;td&gt;all&lt;/td&gt;
&lt;td&gt;the&lt;/td&gt;
&lt;td&gt;days&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;Marie&lt;/td&gt;
&lt;td&gt;ate (imperf.)&lt;/td&gt;
&lt;td&gt;oatmeal&lt;/td&gt;
&lt;td&gt;for&lt;/td&gt;
&lt;td&gt;breakfast&lt;/td&gt;
&lt;td&gt;every&lt;/td&gt;
&lt;td&gt;day&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Here, we have two different tenses for actions in the past which were repeated or more general, and those which are more specific instances. These same tenses (imperfect and perfect) relate also to time duration annotations, which can be found in the UDS dataset &lt;span class=&#34;citation&#34;&gt;(White et al. 2019)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;awarenesssentience&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Awareness/sentience&lt;/h2&gt;
&lt;p&gt;Awareness and sentience are probably my favorite proto-roles; what could better describe the impressive human capacity for language than the entirely unconscious ability to rapidly draw inferences about philosophically layered concepts like awareness and sentience? German (another morphologically rich language) makes certain inferences about awareness and sentience quite clear in its use of case with certain verbs. In English, a speaker surprised by something might say:&lt;/p&gt;
&lt;ol start=&#34;5&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;I don&#39;t believe &lt;em&gt;it&lt;/em&gt;!&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;While an incredulous person might say:&lt;/p&gt;
&lt;ol start=&#34;6&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;I don&#39;t believe &lt;em&gt;him&lt;/em&gt;!&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;where the &amp;quot;it&amp;quot; in (5) is clearly non-sentient (i.e. a news story, a state of affairs, a juicy piece of gossip, etc.) while &amp;quot;him&amp;quot; in (6) is sentient. In German, these two objects, while arguments of the same verb, take different cases (accusative and dative, respectively):&lt;/p&gt;
&lt;ol start=&#34;5&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;Ich&lt;/th&gt;
&lt;th&gt;glaube&lt;/th&gt;
&lt;th&gt;&lt;em&gt;es&lt;/em&gt;&lt;/th&gt;
&lt;th&gt;nicht!&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;I&lt;/td&gt;
&lt;td&gt;believe&lt;/td&gt;
&lt;td&gt;it-ACC&lt;/td&gt;
&lt;td&gt;not&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;I&lt;/td&gt;
&lt;td&gt;don&#39;t&lt;/td&gt;
&lt;td&gt;believe&lt;/td&gt;
&lt;td&gt;it&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;&lt;/li&gt;
&lt;li&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;Ich&lt;/th&gt;
&lt;th&gt;glaube&lt;/th&gt;
&lt;th&gt;&lt;em&gt;ihm&lt;/em&gt;&lt;/th&gt;
&lt;th&gt;nicht!&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;I&lt;/td&gt;
&lt;td&gt;believe&lt;/td&gt;
&lt;td&gt;him-DAT&lt;/td&gt;
&lt;td&gt;not&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;I&lt;/td&gt;
&lt;td&gt;don&#39;t&lt;/td&gt;
&lt;td&gt;believe&lt;/td&gt;
&lt;td&gt;him&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;A German speaker thus explicitly represents beliefs about the sentience/non-sentience of an object while choosing a case for an object.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusions&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Conclusions&lt;/h1&gt;
&lt;p&gt;By no means am I suggesting, with the examples above, that these inferences are impossible to draw in different languages, or even necessarily more difficult. All languages are infinitely expressive, and given enough clarification, any inferences about proto-roles, genericity, time duration, or word sense can be made as plain as in any other language. I instead hope to draw attention to the ways that languages encode some of these inferences explicitly in the grammar, lending support to their status as real linguistic concepts rather than figments of the imagination.&lt;/p&gt;
&lt;p&gt;Nor do I want to give the impression that speakers of these different languages differ in their judgements of these inferences, or that having the inferences explicitly represented in the grammar or morphology somehow increases our awareness of them. I don&#39;t know of any research to this effect, and have not experienced this myself. In fact, the miracle is that all of this happens largely unconsciously, and that there seems to be wide agreement between speakers on these inferences. That all speakers of a language can even agree on a meaning for what &lt;em&gt;is&lt;/em&gt; said is miraculous, but that they can also to a large extent on what is &lt;em&gt;not&lt;/em&gt; said is even more astounding.&lt;/p&gt;
&lt;p&gt;Finally, these are just &lt;em&gt;some&lt;/em&gt; examples from &lt;em&gt;some&lt;/em&gt; languages that I happen to be familiar with. I&#39;d love to find more examples like these, so if you can think of ones in other languages (especially non-&lt;a href=&#34;https://en.wikipedia.org/wiki/Psychology#WEIRD_bias&#34;&gt;WEIRD&lt;/a&gt; languages!) please don&#39;t hesitate to reach out! Similarly, if you can think of counter-examples in these languages or others, shoot me a message.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references&#34;&gt;
&lt;div id=&#34;ref-dowty.d.1991&#34;&gt;
&lt;p&gt;Dowty, David. 1991. “Thematic Proto-Roles and Argument Selection.” &lt;em&gt;Language&lt;/em&gt; 67 (3). Linguistic Society of America: 547–619.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-govindarajan.v.2019&#34;&gt;
&lt;p&gt;Govindarajan, Venkata, Benjamin Van Durme, and Aaron Steven White. 2019. “Decomposing Generalization: Models of Generic, Habitual, and Episodic Statements.” &lt;em&gt;Transactions of the Association for Computational Linguistics&lt;/em&gt; 7: 501–17.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-reisinger.d.2015&#34;&gt;
&lt;p&gt;Reisinger, Drew, Rachel Rudinger, Francis Ferraro, Craig Harman, Kyle Rawlins, and Benjamin Van Durme. 2015. “Semantic Proto-Roles.” &lt;em&gt;Transactions of the Association for Computational Linguistics&lt;/em&gt; 3: 475–88.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-stengel-eskin.e.2020&#34;&gt;
&lt;p&gt;Stengel-Eskin, Elias, Aaron Steven White, Sheng Zhang, and Benjamin Van Durme. 2020. “Universal Decompositional Semantic Parsing.” In &lt;em&gt;Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics&lt;/em&gt;, 8427–39. Online: Association for Computational Linguistics. &lt;a href=&#34;https://www.aclweb.org/anthology/2020.acl-main.746&#34; class=&#34;uri&#34;&gt;https://www.aclweb.org/anthology/2020.acl-main.746&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-vaish.a.2010&#34;&gt;
&lt;p&gt;Vaish, Amrisha, Malinda Carpenter, and Michael Tomasello. 2010. “Young Children Selectively Avoid Helping People with Harmful Intentions.” &lt;em&gt;Child Development&lt;/em&gt; 81 (6). Wiley Online Library: 1661–9.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-vashishtha.s.2019&#34;&gt;
&lt;p&gt;Vashishtha, Siddharth, Benjamin Van Durme, and Aaron Steven White. 2019. “Fine-Grained Temporal Relation Extraction.” In &lt;em&gt;Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics&lt;/em&gt;, 2906–19. Florence, Italy: Association for Computational Linguistics.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-white.a.2016&#34;&gt;
&lt;p&gt;White, Aaron Steven, Drew Reisinger, Keisuke Sakaguchi, Tim Vieira, Sheng Zhang, Rachel Rudinger, Kyle Rawlins, and Benjamin Van Durme. 2016. “Universal Decompositional Semantics on Universal Dependencies.” In &lt;em&gt;Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing&lt;/em&gt;, 1713–23. Austin, TX: Association for Computational Linguistics.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-white.a.2019&#34;&gt;
&lt;p&gt;White, Aaron Steven, Elias Stengel-Eskin, Siddharth Vashishtha, Venkata Govindarajan, Dee Ann Reisinger, Tim Vieira, Keisuke Sakaguchi, et al. 2019. “The Universal Decompositional Semantics Dataset and Decomp Toolkit.” &lt;em&gt;ArXiv Preprint ArXiv:1909.13851&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;based on the finding that toddlers show preferences for helping individuals who are perceived to have caused a harmful action accidentally over those who caused the same action on purpose&lt;a href=&#34;#fnref1&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;Where needed, I&#39;ve included a linguistic gloss (basically a word-for-word translation), with cases like NOM (nominative), ACC (accusative), DAT (dative), etc., as well as a &amp;quot;rough gloss&amp;quot; which gives a more English-ified word-for-word translation of the original sentence, to be more comprehensible for those who aren&#39;t familiar with the case system.&lt;a href=&#34;#fnref2&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;I specify the active voice, since we often use the passive voice to indicate a lack of volition, i.e. &amp;quot;The plate was broken by Derek,&amp;quot; although this isn&#39;t quite the same as the Spanish and German examples. We also have verbs that optionally take an object, like &amp;quot;break,&amp;quot; that can be used to express a similar notion, i.e. &amp;quot;The plate broke,&amp;quot; but there is no easy way to simultaneously express Derek&#39;s involvement.&lt;a href=&#34;#fnref3&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn4&#34;&gt;&lt;p&gt;&lt;em&gt;cui bono&lt;/em&gt; is actually a rare &amp;quot;double dative&amp;quot; composed of a &lt;em&gt;dative of advantage&lt;/em&gt; and a &lt;em&gt;dative of reference&lt;/em&gt;, literally, &amp;quot;for a benefit to whom?&amp;quot;&lt;a href=&#34;#fnref4&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Universal Decompositional Semantic Parsing</title>
      <link>/publication/2020-decomp-model/</link>
      <pubDate>Mon, 08 Jun 2020 00:00:00 +0000</pubDate>
      <guid>/publication/2020-decomp-model/</guid>
      <description></description>
    </item>
    
    <item>
      <title>The Universal Decompositional Semantics Dataset and Decomp Toolkit</title>
      <link>/publication/2020-decomp-dataset/</link>
      <pubDate>Mon, 11 May 2020 00:00:00 +0000</pubDate>
      <guid>/publication/2020-decomp-dataset/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Deep Learning Fundamentals</title>
      <link>/talk/2019-lectures/</link>
      <pubDate>Tue, 19 Nov 2019 00:00:00 +0000</pubDate>
      <guid>/talk/2019-lectures/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A Discriminative Neural Model for Cross-Lingual Word Alignment</title>
      <link>/publication/2019-alignment/</link>
      <pubDate>Sun, 03 Nov 2019 00:00:00 +0000</pubDate>
      <guid>/publication/2019-alignment/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Philosophy of Language for NLP</title>
      <link>/talk/2019-phil/</link>
      <pubDate>Fri, 25 Oct 2019 00:00:00 +0000</pubDate>
      <guid>/talk/2019-phil/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Semantic Eval for MT</title>
      <link>/talk/2019-eval/</link>
      <pubDate>Fri, 26 Apr 2019 00:00:00 +0000</pubDate>
      <guid>/talk/2019-eval/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Attention and Alignment</title>
      <link>/talk/2018-alignment/</link>
      <pubDate>Fri, 09 Nov 2018 00:00:00 +0000</pubDate>
      <guid>/talk/2018-alignment/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Polyglot and Speech Corpus Tools: A System for Representing, Integrating, and Querying Speech Corpora.</title>
      <link>/publication/2017-polyglot/</link>
      <pubDate>Thu, 24 Aug 2017 00:00:00 +0000</pubDate>
      <guid>/publication/2017-polyglot/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
